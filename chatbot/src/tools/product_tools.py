import pandas as pd
from sqlalchemy import create_engine, text
from typing import Optional, List, Dict, Any
import requests
import os
import numpy as np
import json 
import re
from rag.retrieve import search_elasticsearch,search_name
from dotenv import load_dotenv
from models.requirements import *
from llama_index.llms.openai import OpenAI
from prompts import *
import sys
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))
from db.mysql import mysql
from db.mongodb import mongodb
from google.adk.tools import ToolContext
from share_data import current_group_ids,filter_params
from tools.cart_tools import find_group_id_by_product_id
import traceback

load_dotenv("../.env")
llm = OpenAI(
    model="gpt-4o-mini",  
    api_key=os.getenv("OPENAI_API_KEY"),
)
def product_consultation_tool(device: str, query: str, top_k: int = 5) -> str:
    """
    C√¥ng c·ª• t∆∞ v·∫•n s·∫£n ph·∫©m ƒëi·ªán t·ª≠ th√¥ng minh d·ª±a tr√™n nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng.
    
    Args:
        device (str): Lo·∫°i thi·∫øt b·ªã c·∫ßn t∆∞ v·∫•n (v√≠ d·ª•: "phone", "laptop", "tablet", "wired_earphone": , "smartwatch")
        query (str): C√¢u h·ªèi ho·∫∑c y√™u c·∫ßu t∆∞ v·∫•n g·ªëc c·ªßa ng∆∞·ªùi d√πng (v√≠ d·ª•: "t√¨m ƒëi·ªán tho·∫°i ch·ª•p ·∫£nh ƒë·∫πp d∆∞·ªõi 15 tri·ªáu", "laptop gaming trong t·∫ßm gi√° 20-30 tri·ªáu")
        top_k (int, optional): Top s·ªë l∆∞·ª£ng s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t m√† ng∆∞·ªùi d√πng mu·ªën hi·ªÉn th·ªã trong k·∫øt qu·∫£ t∆∞ v·∫•n. 
                               
    Returns:
        str: K·∫øt qu·∫£ t∆∞ v·∫•n chi ti·∫øt bao g·ªìm danh s√°ch s·∫£n ph·∫©m ph√π h·ª£p    
    Examples:
        >>> # T∆∞ v·∫•n 3 ƒëi·ªán tho·∫°i t·ªët nh·∫•t
        >>> product_consultation_tool("phone", "ch·ª•p ·∫£nh ƒë·∫πp d∆∞·ªõi 15 tri·ªáu", top_k=3)
        
        >>> # Xem 10 laptop gaming ƒë·ªÉ c√≥ nhi·ªÅu l·ª±a ch·ªçn
        >>> product_consultation_tool("laptop", "gaming trong t·∫ßm 20-30 tri·ªáu", top_k=10)
        
    """
    current_group_ids.clear()
    filter_params.clear()
    try:
        conn = mysql.connect()
        cursor = conn.cursor()
        
        # Process device type
        if device == "phone":
            reqs = llm.structured_predict(PhoneRequirements, PHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "phone"
        elif device == "laptop":
            reqs = llm.structured_predict(LaptopRequirements, LAPTOP_CONSULTATION_TEMPLATE, query=query)
            device_type = "laptop"
        elif device == "wired_earphone":
            reqs = llm.structured_predict(WiredEarphoneRequirements, WIRED_EARPHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "wired_earphone"
        elif device == "wireless_earphone":
            reqs = llm.structured_predict(WirelessEarphoneRequirements, WIRELESS_EARPHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "wireless_earphone"
        elif device == "headphone":
            reqs = llm.structured_predict(HeadphoneRequirements, HEADPHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "headphone"
        elif device == "backup_charger":
            reqs = llm.structured_predict(BackupChargerRequirements, BACKUPCHARGER_CONSULTATION_TEMPLATE, query=query)
            device_type = "backup_charger"
        else:
            cursor.close()
            conn.close()
            return "Lo·∫°i s·∫£n ph·∫©m n√†y hi·ªán t·∫°i ch∆∞a c√≥ t·∫°i c·ª≠a h√†ng ch√∫ng t√¥i."

        # L∆∞u c√°c tham s·ªë filter v√†o filter_params
        filter_params.update({
            "type": device_type,
        })

        # X·ª≠ l√Ω ng√¢n s√°ch
        if reqs.min_budget:
            filter_params["minPrice"] = reqs.min_budget
        if reqs.max_budget:
            filter_params["maxPrice"] = reqs.max_budget

        # X·ª≠ l√Ω brand preference (string v·ªõi d·∫•u ph·∫©y)
        if reqs.brand_preference and reqs.brand_preference.strip():
            filter_params["brand"] = reqs.brand_preference

        # *** FIX: GI·ªÆ NGUY√äN T√äN TAG THEO MODEL REQUIREMENTS ***
        # Thu th·∫≠p t·∫•t c·∫£ c√°c tags ƒë∆∞·ª£c ƒë√°nh d·∫•u True trong model requirements
        active_tags = []
        for field_name, value in reqs.dict().items():
            # B·ªè qua c√°c field kh√¥ng ph·∫£i tag (min_budget, max_budget, brand_preference, specific_requirements)
            if field_name not in ['min_budget', 'max_budget', 'brand_preference', 'specific_requirements'] and value:
                # Gi·ªØ nguy√™n t√™n field t·ª´ model requirements
                active_tags.append(field_name)
        
        if active_tags:
            filter_params["tags"] = ",".join(active_tags)

        # X·ª≠ l√Ω specific requirements (t√¨m ki·∫øm full-text)
        if reqs.specific_requirements:
            filter_params["search"] = reqs.specific_requirements

        # Parse brand_preference string th√†nh list
        brand_list = []
        brand_display = ""
        if reqs.brand_preference and reqs.brand_preference.strip():
            # Split by comma v√† clean up
            brand_list = [brand.strip() for brand in reqs.brand_preference.split(',') if brand.strip() and brand.strip() != "kh√¥ng x√°c ƒë·ªãnh"]
            if brand_list:
                brand_display = ", ".join(brand_list)
        
        min_budget = reqs.min_budget
        max_budget = reqs.max_budget
        print(reqs)
        
        # **X·ª¨ L√ù BRAND FILTER CHO COMMA-SEPARATED STRING**
        brand_filtered_df = None
        if brand_list:
            # Create placeholders for IN clause
            brand_placeholders = ','.join(['%s'] * len(brand_list))
            brand_sql = f"""
                SELECT group_id, group_name, brand
                FROM group_product
                WHERE brand IN ({brand_placeholders}) AND type = %s
            """
            brand_params = brand_list + [device_type]
            cursor.execute(brand_sql, brand_params)
            brand_result = cursor.fetchall()
            
            if brand_result:
                brand_filtered_df = pd.DataFrame(brand_result, columns=["group_id", "group_name", "brand"])
                print(f"Found {len(brand_filtered_df)} products for brands {brand_list}")
            else:
                cursor.close()
                conn.close()
                if len(brand_list) == 1:
                    return f"Kh√¥ng t√¨m th·∫•y {device} c·ªßa th∆∞∆°ng hi·ªáu {brand_list[0]} trong c·ª≠a h√†ng."
                else:
                    brands_str = " ho·∫∑c ".join(brand_list)
                    return f"Kh√¥ng t√¨m th·∫•y {device} c·ªßa th∆∞∆°ng hi·ªáu {brands_str} trong c·ª≠a h√†ng."
        
        # Ki·ªÉm tra n·∫øu ch·ªâ c√≥ th√¥ng tin gi√° m√† kh√¥ng c√≥ y√™u c·∫ßu kh√°c
        only_price = (min_budget or max_budget) and not any(
            field for field in reqs.__dict__.keys() 
            if field not in ['min_budget', 'max_budget', 'brand_preference', 'specific_requirements'] and getattr(reqs, field)
        )
        
        if only_price:
            # Tr∆∞·ªùng h·ª£p ch·ªâ c√≥ th√¥ng tin gi√°
            if brand_filtered_df is not None:
                # N·∫øu c√≥ brand filter, ch·ªâ l·∫•y gi√° c·ªßa c√°c s·∫£n ph·∫©m trong brand ƒë√≥
                brand_group_ids = brand_filtered_df['group_id'].tolist()
                placeholders = ','.join(['%s'] * len(brand_group_ids))
                price_sql = f"""
                    SELECT gp.group_id, gp.group_name, MIN(gpj.default_current_price) AS price
                    FROM group_product gp
                    JOIN group_product_junction gpj ON gp.group_id = gpj.group_id
                    WHERE gp.group_id IN ({placeholders})
                    GROUP BY gp.group_id, gp.group_name
                """
                cursor.execute(price_sql, brand_group_ids)
            else:
                # Kh√¥ng c√≥ brand filter, l·∫•y t·∫•t c·∫£
                price_sql = """
                    SELECT gp.group_id, gp.group_name, MIN(gpj.default_current_price) AS price
                    FROM group_product gp
                    JOIN group_product_junction gpj ON gp.group_id = gpj.group_id
                    WHERE gp.type = %s
                    GROUP BY gp.group_id, gp.group_name
                """
                cursor.execute(price_sql, (device_type,))
                
            result = cursor.fetchall()
            combined_df = pd.DataFrame(result, columns=["group_id", "group_name", "price"])
            
            # L·ªçc theo gi√°
            if min_budget:
                combined_df = combined_df[combined_df["price"] >= min_budget]
            if max_budget and max_budget != 0:
                combined_df = combined_df[combined_df["price"] <= max_budget]
                
            # S·∫Øp x·∫øp theo gi√° t·ª´ CAO NH·∫§T ƒë·∫øn TH·∫§P NH·∫§T
            combined_df = combined_df.sort_values(by="price", ascending=False).head(top_k)
            
            if combined_df.empty:
                cursor.close()
                conn.close()
                brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
                return f"Kh√¥ng t√¨m th·∫•y {device}{brand_msg} ph√π h·ª£p v·ªõi kho·∫£ng gi√° b·∫°n y√™u c·∫ßu."
            
            # **FIX: TH√äM GROUP_IDS V√ÄO CURRENT_GROUP_IDS**
            current_group_ids.extend(combined_df['group_id'].tolist())
            
            # Build response
            brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
            response = f"D∆∞·ªõi ƒë√¢y l√† top {top_k} {device}{brand_msg} ph√π h·ª£p v·ªõi kho·∫£ng gi√° b·∫°n y√™u c·∫ßu (t·ª´ cao ƒë·∫øn th·∫•p):\n"
            for _, product in combined_df.iterrows():
                product_info = f"- {product['group_name']} (ID: {product['group_id']}, gi√°: {int(product['price']):,} ƒë·ªìng)"
                response += product_info + "\n"
            
            cursor.close()
            conn.close()
            return response

        # N·∫øu c√≥ y√™u c·∫ßu kh√°c ngo√†i gi√°, x·ª≠ l√Ω nh∆∞ b√¨nh th∆∞·ªùng
        # Active requirements - ch·ªâ l·∫•y c√°c field l√† tag (b·ªè qua budget, brand, specific)
        req_fields = [field for field in reqs.__dict__.keys() 
                     if field not in ['min_budget', 'max_budget', 'brand_preference', 'specific_requirements'] 
                     and getattr(reqs, field)]

        # Query tags v·ªõi brand filter
        tables_to_merge = []
        
        for req_key in req_fields:
            tag_name = req_key  # Gi·ªØ nguy√™n t√™n t·ª´ model requirements
            if brand_filtered_df is not None:
                # N·∫øu c√≥ brand filter, ch·ªâ l·∫•y tags c·ªßa c√°c s·∫£n ph·∫©m trong brand ƒë√≥
                brand_group_ids = brand_filtered_df['group_id'].tolist()
                placeholders = ','.join(['%s'] * len(brand_group_ids))
                sql = f"""
                    SELECT gp.group_id, gp.group_name
                    FROM group_product gp
                    JOIN group_tags gt ON gp.group_id = gt.group_id
                    JOIN tags t ON gt.tag_id = t.tag_id
                    WHERE t.tag_name = %s AND gp.group_id IN ({placeholders})
                """
                params = [tag_name] + brand_group_ids
                cursor.execute(sql, params)
            else:
                # Kh√¥ng c√≥ brand filter
                sql = """
                    SELECT gp.group_id, gp.group_name
                    FROM group_product gp
                    JOIN group_tags gt ON gp.group_id = gt.group_id
                    JOIN tags t ON gt.tag_id = t.tag_id
                    WHERE t.tag_name = %s AND gp.type = %s
                """
                cursor.execute(sql, (tag_name, device_type))
                
            result = cursor.fetchall()
            if result:
                df = pd.DataFrame(result, columns=["group_id", "group_name"])
                df[f"{tag_name}_rank"] = df.index + 1
                tables_to_merge.append(df[["group_id", "group_name", f"{tag_name}_rank"]])

        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ch·ªâ c√≥ brand preference kh√¥ng c√≥ tag
        if not tables_to_merge:
            if brand_filtered_df is not None:
                # N·∫øu ch·ªâ c√≥ brand preference m√† kh√¥ng c√≥ tag n√†o, s·ª≠ d·ª•ng brand_filtered_df
                combined_df = brand_filtered_df.copy()
                # **FIX: TH√äM CURRENT_GROUP_IDS CHO TR∆Ø·ªúNG H·ª¢P CH·ªà C√ì BRAND**
                current_group_ids.extend(combined_df['group_id'].tolist())
            else:
                cursor.close()
                conn.close()
                return f"T√¥i ƒë·ªÅ xu·∫•t {device} t·ª´ {brand_display} d·ª±a tr√™n s·ªü th√≠ch th∆∞∆°ng hi·ªáu c·ªßa b·∫°n." if brand_display else f"T√¥i c·∫ßn th√™m th√¥ng tin ƒë·ªÉ ƒë·ªÅ xu·∫•t {device} ph√π h·ª£p."
        else:
            # Merge DataFrames
            combined_df = tables_to_merge[0]
            for df in tables_to_merge[1:]:
                combined_df = pd.merge(combined_df, df, on=["group_id", "group_name"], how="inner")

            # Fill NaN ranks
            max_rank = max([len(df) for df in tables_to_merge]) + 1
            for col in combined_df.columns:
                if col.endswith("_rank"):
                    combined_df[col] = combined_df[col].fillna(max_rank)

        # X·ª≠ l√Ω specific_requirements
        if hasattr(reqs, 'specific_requirements') and reqs.specific_requirements and reqs.specific_requirements != '':
            print("reqs.specific_requirements", reqs.specific_requirements)
            
            # L·∫•y danh s√°ch group_id t·ª´ combined_df
            group_ids = combined_df['group_id'].astype(str).tolist()
            
            # T√¨m ki·∫øm ch√≠nh x√°c c·ª•m t·ª´
            search_results = search_elasticsearch(
                query=reqs.specific_requirements,
                ids=group_ids,
                size=len(group_ids)
            )
            print('search_results', search_results)
            
            # T·∫°o mapping ƒëi·ªÉm s·ªë t·ª´ k·∫øt qu·∫£ search
            relevance_scores = {}
            if search_results:
                for hit in search_results:
                    group_id = int(hit['group_id'])
                    score = hit.get('_score', 0)  # L·∫•y ƒëi·ªÉm t·ª´ Elasticsearch
                    relevance_scores[group_id] = score
            
            # Th√™m c·ªôt ƒëi·ªÉm relevance cho t·∫•t c·∫£ s·∫£n ph·∫©m
            # N·∫øu group_id kh√¥ng c√≥ trong k·∫øt qu·∫£ search th√¨ ƒë∆∞·ª£c g√°n ƒëi·ªÉm 0
            combined_df['relevance_score'] = combined_df['group_id'].map(
                lambda x: relevance_scores.get(x, 0)
            )
            
            # S·∫Øp x·∫øp theo ƒëi·ªÉm relevance (cao nh·∫•t tr∆∞·ªõc)
            combined_df = combined_df.sort_values('relevance_score', ascending=False)
            
            print(f"Reranked {len(combined_df)} products by specific requirements relevance")
            
        # X·ª≠ l√Ω gi√° c·∫£
        if min_budget or max_budget:
            if not combined_df.empty:
                group_ids_for_price = combined_df['group_id'].tolist()
                placeholders = ','.join(['%s'] * len(group_ids_for_price))
                price_sql = f"""
                    SELECT gpj.group_id, gp.group_name, gpj.default_current_price AS price
                    FROM group_product_junction gpj
                    JOIN group_product gp ON gpj.group_id = gp.group_id
                    WHERE gpj.group_id IN ({placeholders})
                    AND (gpj.group_id, gpj.default_current_price) IN (
                        SELECT group_id, MIN(default_current_price)
                        FROM group_product_junction
                        WHERE group_id IN ({placeholders})
                        GROUP BY group_id
                    )
                """
                params = group_ids_for_price + group_ids_for_price
                cursor.execute(price_sql, params)
                result = cursor.fetchall()
                prices_df = pd.DataFrame(result, columns=["group_id", "group_name", "price"])

                if not prices_df.empty:
                    combined_df = pd.merge(combined_df, prices_df, on=["group_id", "group_name"], how="inner")
                    if min_budget:
                        combined_df = combined_df[combined_df["price"] >= min_budget]
                    if max_budget and max_budget != 0:
                        combined_df = combined_df[combined_df["price"] <= max_budget]

        # Calculate ranks
        rank_columns = [col for col in combined_df.columns if col.endswith("_rank")]
        if "es_rank" in combined_df.columns:
            rank_columns.append("es_rank")
            
        if rank_columns:
            combined_df["combined_rank"] = combined_df[rank_columns].sum(axis=1)
            top_k_products = combined_df.sort_values(by="combined_rank").head(top_k)
        else:
            # N·∫øu kh√¥ng c√≥ rank columns, l·∫•y theo th·ª© t·ª±
            top_k_products = combined_df.head(top_k)
        
        # **FIX: ƒê·∫¢M B·∫¢O CURRENT_GROUP_IDS LU√îN ƒê∆Ø·ª¢C C·∫¨P NH·∫¨T**
        if not top_k_products.empty:
            current_group_ids.extend(top_k_products['group_id'].tolist())
        
        if top_k_products.empty:
            cursor.close()
            conn.close()
            brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
            return f"Kh√¥ng t√¨m th·∫•y {device}{brand_msg} ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n."

        # Build response
        brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
        response = f"D∆∞·ªõi ƒë√¢y l√† top {top_k} {device}{brand_msg} ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n:\n"
        for _, product in top_k_products.iterrows():
            product_info = f"- {product['group_name']} (ID: {product['group_id']}"
            if "combined_rank" in product and not pd.isna(product["combined_rank"]):
                product_info += f", rank: {int(product['combined_rank'])}"
            if "price" in product and not pd.isna(product["price"]):
                product_info += f", gi√°: {int(product['price']):,} ƒë·ªìng"
            product_info += ")"
            response += product_info + "\n"
        cursor.close()
        conn.close()
        return response

    except Exception as e:
        try:
            cursor.close()
            conn.close()
        except:
            pass
        return f"L·ªói: {e}"
    

def product_information_tool(query: str) -> str:
    current_group_ids.clear()
        
    # Split and clean product names
    product_names = [name.strip() for name in query.split(',') if name.strip()]
    if not product_names:
        return "Vui l√≤ng cung c·∫•p t√™n s·∫£n ph·∫©m c√°ch nhau b·∫±ng d·∫•u ph·∫©y."

    output = []
    score_threshold_percent = 0.10  # 10% threshold

    for product_name in product_names:
        # Search for each product
        results = search_name(product_name)
        if not results:
            output.append(f"Kh√¥ng t√¨m th·∫•y th√¥ng tin cho s·∫£n ph·∫©m: {product_name}")
            continue

        # Sort results by score (descending)
        results.sort(key=lambda x: x.get('score', 0), reverse=True)
        top_score = results[0].get('score', 0)
        min_score = top_score * (1 - score_threshold_percent)

        # Filter results within 10% of top score
        qualified_results = [r for r in results if r.get('score', 0) >= min_score]
        if not qualified_results:
            output.append(f"Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªß t·ªët cho s·∫£n ph·∫©m: {product_name}")
            continue

        # Add product information to output
        output.append(f"\n=== K·∫øt qu·∫£ tham kh·∫£o cho '{product_name}' ===")
        for i, r in enumerate(qualified_results, 1):
            output.append(f"\nS·∫£n ph·∫©m {i}:")
            output.append(r.get('document', 'Th√¥ng tin kh√¥ng kh·∫£ d·ª•ng'))
            output.append(f"ƒê·ªô ph√π h·ª£p: {r.get('score', 0):.2f} (Top score: {top_score:.2f})")
            
            if group_id := r.get('group_id'):
                current_group_ids.append(group_id)
    print(current_group_ids)
    if len(output) == 0:
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p cho b·∫•t k·ª≥ s·∫£n ph·∫©m n√†o."
    return "\n".join(output)




def product_information_tool_for_cart(query: str) -> str:
    current_group_ids.clear()
        
    # Split and clean product names
    product_names = [name.strip() for name in query.split(',') if name.strip()]
    if not product_names:
        return "Vui l√≤ng cung c·∫•p t√™n s·∫£n ph·∫©m c√°ch nhau b·∫±ng d·∫•u ph·∫©y."

    output = []
    score_threshold_percent = 0.4  # 40% threshold

    for product_name in product_names:
        # Search for each product
        results = search_name(product_name, size=3)
        if not results:
            output.append(f"Kh√¥ng t√¨m th·∫•y th√¥ng tin cho s·∫£n ph·∫©m: {product_name}")
            continue

        # Sort results by score (descending)
        results.sort(key=lambda x: x.get('score', 0), reverse=True)
        top_score = results[0].get('score', 0)
        min_score = top_score * (1 - score_threshold_percent)

        # Filter results within 10% of top score
        qualified_results = [r for r in results if r.get('score', 0) >= min_score]
        if not qualified_results:
            output.append(f"Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªß t·ªët cho s·∫£n ph·∫©m: {product_name}")
            continue

        # Add product information to output
        output.append(f"\n=== K·∫øt qu·∫£ tham kh·∫£o cho '{product_name}' ===")
        for i, r in enumerate(qualified_results, 1):
            output.append(f"\nS·∫£n ph·∫©m {i}:")
            output.append(r.get('document', 'Th√¥ng tin kh√¥ng kh·∫£ d·ª•ng'))
            output.append(f"ƒê·ªô ph√π h·ª£p: {r.get('score', 0):.2f} (Top score: {top_score:.2f})")
            output.append(f"group_id: {r.get('group_id')}")
            if group_id := r.get('group_id'):
                current_group_ids.append(group_id)
    print(current_group_ids)
    if len(output) == 0:
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p cho b·∫•t k·ª≥ s·∫£n ph·∫©m n√†o."
    return "\n".join(output)



def product_consultation_tool_mongo(device: str, query: str, top_k: int = 5) -> str:
    """
    C√¥ng c·ª• t∆∞ v·∫•n s·∫£n ph·∫©m s·ª≠ d·ª•ng MongoDB search thay v√¨ Elasticsearch cho specific_requirements.
    
    Args:
        device (str): Lo·∫°i thi·∫øt b·ªã c·∫ßn t∆∞ v·∫•n (v√≠ d·ª•: "phone", "laptop", "tablet", "wired_earphone", "smartwatch")
        query (str): C√¢u h·ªèi ho·∫∑c y√™u c·∫ßu t∆∞ v·∫•n g·ªëc c·ªßa ng∆∞·ªùi d√πng
        top_k (int, optional): Top s·ªë l∆∞·ª£ng s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t
                               
    Returns:
        str: K·∫øt qu·∫£ t∆∞ v·∫•n chi ti·∫øt bao g·ªìm danh s√°ch s·∫£n ph·∫©m ph√π h·ª£p    
    """
    current_group_ids.clear()
    filter_params.clear()
    try:
        conn = mysql.connect()
        cursor = conn.cursor()
        
        # Process device type v√† extract requirements gi·ªëng h√†m c≈©
        if device == "phone":
            reqs = llm.structured_predict(PhoneRequirements, PHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "phone"
        elif device == "laptop":
            reqs = llm.structured_predict(LaptopRequirements, LAPTOP_CONSULTATION_TEMPLATE, query=query)
            device_type = "laptop"
        elif device == "wired_earphone":
            reqs = llm.structured_predict(WiredEarphoneRequirements, WIRED_EARPHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "wired_earphone"
        elif device == "wireless_earphone":
            reqs = llm.structured_predict(WirelessEarphoneRequirements, WIRELESS_EARPHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "wireless_earphone"
        elif device == "headphone":
            reqs = llm.structured_predict(HeadphoneRequirements, HEADPHONE_CONSULTATION_TEMPLATE, query=query)
            device_type = "headphone"
        elif device == "backup_charger":
            reqs = llm.structured_predict(BackupChargerRequirements, BACKUPCHARGER_CONSULTATION_TEMPLATE, query=query)
            device_type = "backup_charger"
        else:
            cursor.close()
            conn.close()
            return "Lo·∫°i s·∫£n ph·∫©m n√†y hi·ªán t·∫°i ch∆∞a c√≥ t·∫°i c·ª≠a h√†ng ch√∫ng t√¥i."

        # L∆∞u c√°c tham s·ªë filter v√†o filter_params
        filter_params.update({"type": device_type})
        if reqs.min_budget:
            filter_params["minPrice"] = reqs.min_budget
        if reqs.max_budget:
            filter_params["maxPrice"] = reqs.max_budget
        if reqs.brand_preference and reqs.brand_preference.strip():
            filter_params["brand"] = reqs.brand_preference

        # Thu th·∫≠p active tags
        active_tags = []
        for field_name, value in reqs.dict().items():
            if field_name not in ['min_budget', 'max_budget', 'brand_preference', 'specific_requirements'] and value:
                active_tags.append(field_name)
        
        if active_tags:
            filter_params["tags"] = ",".join(active_tags)

        # Parse brand_preference
        brand_list = []
        brand_display = ""
        if reqs.brand_preference and reqs.brand_preference.strip():
            brand_list = [brand.strip() for brand in reqs.brand_preference.split(',') if brand.strip() and brand.strip() != "kh√¥ng x√°c ƒë·ªãnh"]
            if brand_list:
                brand_display = ", ".join(brand_list)
        
        min_budget = reqs.min_budget
        max_budget = reqs.max_budget
        print(f"Requirements: {reqs}")
        
        # **BRAND FILTER** - t∆∞∆°ng t·ª± h√†m c≈©
        brand_filtered_df = None
        if brand_list:
            brand_placeholders = ','.join(['%s'] * len(brand_list))
            brand_sql = f"""
                SELECT group_id, group_name, brand
                FROM group_product
                WHERE brand IN ({brand_placeholders}) AND type = %s
            """
            brand_params = brand_list + [device_type]
            cursor.execute(brand_sql, brand_params)
            brand_result = cursor.fetchall()
            
            if brand_result:
                brand_filtered_df = pd.DataFrame(brand_result, columns=["group_id", "group_name", "brand"])
                print(f"Found {len(brand_filtered_df)} products for brands {brand_list}")
            else:
                cursor.close()
                conn.close()
                if len(brand_list) == 1:
                    return f"Kh√¥ng t√¨m th·∫•y {device} c·ªßa th∆∞∆°ng hi·ªáu {brand_list[0]} trong c·ª≠a h√†ng."
                else:
                    brands_str = " ho·∫∑c ".join(brand_list)
                    return f"Kh√¥ng t√¨m th·∫•y {device} c·ªßa th∆∞∆°ng hi·ªáu {brands_str} trong c·ª≠a h√†ng."
        
        # **X·ª¨ L√ù TR∆Ø·ªúNG H·ª¢P CH·ªà C√ì GI√Å** - t∆∞∆°ng t·ª± h√†m c≈©
        only_price = (min_budget or max_budget) and not any(
            field for field in reqs.__dict__.keys() 
            if field not in ['min_budget', 'max_budget', 'brand_preference', 'specific_requirements'] and getattr(reqs, field)
        )
        
        if only_price:
            if brand_filtered_df is not None:
                brand_group_ids = brand_filtered_df['group_id'].tolist()
                placeholders = ','.join(['%s'] * len(brand_group_ids))
                price_sql = f"""
                    SELECT gp.group_id, gp.group_name, MIN(gpj.default_current_price) AS price
                    FROM group_product gp
                    JOIN group_product_junction gpj ON gp.group_id = gpj.group_id
                    WHERE gp.group_id IN ({placeholders})
                    GROUP BY gp.group_id, gp.group_name
                """
                cursor.execute(price_sql, brand_group_ids)
            else:
                price_sql = """
                    SELECT gp.group_id, gp.group_name, MIN(gpj.default_current_price) AS price
                    FROM group_product gp
                    JOIN group_product_junction gpj ON gp.group_id = gpj.group_id
                    WHERE gp.type = %s
                    GROUP BY gp.group_id, gp.group_name
                """
                cursor.execute(price_sql, (device_type,))
                
            result = cursor.fetchall()
            combined_df = pd.DataFrame(result, columns=["group_id", "group_name", "price"])
            
            if min_budget:
                combined_df = combined_df[combined_df["price"] >= min_budget]
            if max_budget and max_budget != 0:
                combined_df = combined_df[combined_df["price"] <= max_budget]
                
            combined_df = combined_df.sort_values(by="price", ascending=False).head(top_k)
            
            if combined_df.empty:
                cursor.close()
                conn.close()
                brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
                return f"Kh√¥ng t√¨m th·∫•y {device}{brand_msg} ph√π h·ª£p v·ªõi kho·∫£ng gi√° b·∫°n y√™u c·∫ßu."
            
            current_group_ids.extend(combined_df['group_id'].tolist())
            
            brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
            response = f"D∆∞·ªõi ƒë√¢y l√† top {top_k} {device}{brand_msg} ph√π h·ª£p v·ªõi kho·∫£ng gi√° b·∫°n y√™u c·∫ßu (t·ª´ cao ƒë·∫øn th·∫•p):\n"
            for _, product in combined_df.iterrows():
                product_info = f"- {product['group_name']} (ID: {product['group_id']}, gi√°: {int(product['price']):,} ƒë·ªìng)"
                response += product_info + "\n"
            
            cursor.close()
            conn.close()
            return response

        # **X·ª¨ L√ù TAGS** - t∆∞∆°ng t·ª± h√†m c≈©
        req_fields = [field for field in reqs.__dict__.keys() 
                     if field not in ['min_budget', 'max_budget', 'brand_preference', 'specific_requirements'] 
                     and getattr(reqs, field)]

        tables_to_merge = []
        
        for req_key in req_fields:
            tag_name = req_key
            if brand_filtered_df is not None:
                brand_group_ids = brand_filtered_df['group_id'].tolist()
                placeholders = ','.join(['%s'] * len(brand_group_ids))
                sql = f"""
                    SELECT gp.group_id, gp.group_name
                    FROM group_product gp
                    JOIN group_tags gt ON gp.group_id = gt.group_id
                    JOIN tags t ON gt.tag_id = t.tag_id
                    WHERE t.tag_name = %s AND gp.group_id IN ({placeholders})
                """
                params = [tag_name] + brand_group_ids
                cursor.execute(sql, params)
            else:
                sql = """
                    SELECT gp.group_id, gp.group_name
                    FROM group_product gp
                    JOIN group_tags gt ON gp.group_id = gt.group_id
                    JOIN tags t ON gt.tag_id = t.tag_id
                    WHERE t.tag_name = %s AND gp.type = %s
                """
                cursor.execute(sql, (tag_name, device_type))
                
            result = cursor.fetchall()
            if result:
                df = pd.DataFrame(result, columns=["group_id", "group_name"])
                df[f"{tag_name}_rank"] = df.index + 1
                tables_to_merge.append(df[["group_id", "group_name", f"{tag_name}_rank"]])

        # **X·ª¨ L√ù KHI KH√îNG C√ì TAGS**
        if not tables_to_merge:
            if brand_filtered_df is not None:
                combined_df = brand_filtered_df.copy()
                current_group_ids.extend(combined_df['group_id'].tolist())
            else:
                cursor.close()
                conn.close()
                return f"T√¥i ƒë·ªÅ xu·∫•t {device} t·ª´ {brand_display} d·ª±a tr√™n s·ªü th√≠ch th∆∞∆°ng hi·ªáu c·ªßa b·∫°n." if brand_display else f"T√¥i c·∫ßn th√™m th√¥ng tin ƒë·ªÉ ƒë·ªÅ xu·∫•t {device} ph√π h·ª£p."
        else:
            # Merge DataFrames
            combined_df = tables_to_merge[0]
            for df in tables_to_merge[1:]:
                combined_df = pd.merge(combined_df, df, on=["group_id", "group_name"], how="inner")

            max_rank = max([len(df) for df in tables_to_merge]) + 1
            for col in combined_df.columns:
                if col.endswith("_rank"):
                    combined_df[col] = combined_df[col].fillna(max_rank)

        # **KH·ªûI T·∫†O BI·∫æN CHO MONGODB SEARCH**
        mongo_search_info = {}  # Kh·ªüi t·∫°o s·ªõm ƒë·ªÉ tr√°nh l·ªói
        
        # **SPECIFIC REQUIREMENTS SEARCH v·ªõi MongoDB + Elasticsearch**
        if hasattr(reqs, 'specific_requirements') and reqs.specific_requirements and reqs.specific_requirements != '':
            print(f"Processing specific_requirements: {reqs.specific_requirements}")
            filter_params["search"] = reqs.specific_requirements
            has_price_requirement = bool(min_budget or max_budget)
            
            # **B∆Ø·ªöC 1: Th·ª≠ MongoDB search tr∆∞·ªõc**
            mongo_search_result = mongodb_search_specific_requirements_get_product_ids(
                query=reqs.specific_requirements,
                device_type=device_type,
                top_k=50
            )
            
            mongo_group_ids = []
            
            if mongo_search_result.get("success") and mongo_search_result.get("product_ids"):
                mongo_product_ids = mongo_search_result["product_ids"]
                mongo_search_info = mongo_search_result["search_info"]
                
                # Map product_ids sang group_ids
                for product_id in mongo_product_ids:
                    mysql_result = find_group_id_by_product_id(str(product_id))
                    if mysql_result.get("status") == "success":
                        group_id = mysql_result.get("group_id")
                        if group_id and group_id not in mongo_group_ids:
                            mongo_group_ids.append(group_id)
                
                print(f"MongoDB found {len(mongo_group_ids)} group_ids for specific_requirements")
                print(f"MongoDB search method: {mongo_search_info.get('search_method', 'Unknown')}")
                print(f"Applied conditions: {len(mongo_search_info.get('applied_conditions', []))}")
            
            # **B∆Ø·ªöC 2: N·∫øu MongoDB kh√¥ng c√≥ k·∫øt qu·∫£ ƒë·ªß, d√πng Elasticsearch**
            search_group_ids = []
            if len(mongo_group_ids) ==0:  # Threshold ƒë·ªÉ quy·∫øt ƒë·ªãnh c√≥ d√πng ES hay kh√¥ng
                print("MongoDB results insufficient, trying Elasticsearch...")
                
                try:
                    # L·∫•y group_ids hi·ªán t·∫°i ƒë·ªÉ filter (n·∫øu c√≥)
                    current_group_ids_for_es = None
                    if not combined_df.empty:
                        current_group_ids_for_es = [str(gid) for gid in combined_df['group_id'].tolist()]
                    
                    # T√¨m ki·∫øm b·∫±ng Elasticsearch
                    es_results = search_elasticsearch(
                        query=reqs.specific_requirements,
                        ids=current_group_ids_for_es,  # Filter theo group_ids hi·ªán t·∫°i
                        size=top_k * 2
                    )
                    
                    if es_results:
                        es_group_ids = [int(hit.get('group_id')) for hit in es_results if hit.get('group_id')]
                        print(f"Elasticsearch found {len(es_group_ids)} group_ids")
                        
                        # Combine v·ªõi MongoDB results
                        combined_search_ids = list(set(mongo_group_ids + es_group_ids))
                        search_group_ids = combined_search_ids[:top_k * 2]  # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
                    else:
                        search_group_ids = mongo_group_ids
                except Exception as es_error:
                    print(f"Elasticsearch failed: {str(es_error)}, using MongoDB results only")
                    search_group_ids = mongo_group_ids
            else:
                search_group_ids = mongo_group_ids
                
            print(f"Total search_group_ids: {len(search_group_ids)}")
            
            # **B∆Ø·ªöC 3: X·ª≠ l√Ω k·∫øt qu·∫£ search v·ªõi combined_df**
            if search_group_ids:
                if not combined_df.empty:
                    # C√≥ tags/filters 
                    existing_group_ids = set(combined_df['group_id'].tolist())
                    search_group_ids_set = set(search_group_ids)
                    intersection_group_ids = list(existing_group_ids.intersection(search_group_ids_set))
                    
                    print(f"Intersection: {len(intersection_group_ids)} group_ids (tags: {len(existing_group_ids)}, search: {len(search_group_ids_set)})")
                    
                    if intersection_group_ids:
                        # Filter combined_df ch·ªâ gi·ªØ ph·∫ßn giao
                        combined_df = combined_df[combined_df['group_id'].isin(intersection_group_ids)]
                        
                        # Th√™m relevance score d·ª±a tr√™n th·ª© t·ª± trong search results
                        relevance_scores = {}
                        for i, group_id in enumerate(search_group_ids):
                            if group_id in intersection_group_ids:
                                relevance_scores[group_id] = len(search_group_ids) - i
                        
                        combined_df['relevance_score'] = combined_df['group_id'].map(
                            lambda x: relevance_scores.get(x, 0)
                        )
                        
                        # S·∫Øp x·∫øp theo relevance score
                        combined_df = combined_df.sort_values('relevance_score', ascending=False)
                        print(f"Filtered to intersection and ranked by search relevance")
                    else:
                        print("No intersection between search results and tag filters")
                        
                        if has_price_requirement:
                            # C√≥ y√™u c·∫ßu v·ªÅ gi√° - gi·ªØ nguy√™n combined_df t·ª´ tags
                            print("Has price requirement - keeping tag results")
                            combined_df['relevance_score'] = 1.0
                        else:
                            # Kh√¥ng c√≥ y√™u c·∫ßu v·ªÅ gi√° - ∆∞u ti√™n search results
                            print("No price requirement - prioritizing search results")
                            if search_group_ids:
                                placeholders = ','.join(['%s'] * len(search_group_ids))
                                group_name_sql = f"""
                                    SELECT group_id, group_name 
                                    FROM group_product 
                                    WHERE group_id IN ({placeholders})
                                """
                                cursor.execute(group_name_sql, search_group_ids)
                                group_name_results = cursor.fetchall()
                                
                                combined_df = pd.DataFrame(group_name_results, columns=["group_id", "group_name"])
                                
                                # Th√™m relevance score
                                relevance_scores = {}
                                for i, group_id in enumerate(search_group_ids):
                                    relevance_scores[group_id] = len(search_group_ids) - i
                                
                                combined_df['relevance_score'] = combined_df['group_id'].map(
                                    lambda x: relevance_scores.get(x, 0)
                                )
                                
                                # S·∫Øp x·∫øp theo relevance score
                                combined_df = combined_df.sort_values('relevance_score', ascending=False)
                                print(f"Replaced with search results: {len(combined_df)} products")
                            else:
                                combined_df['relevance_score'] = 1.0
                else:
                    # Kh√¥ng c√≥ tags/filters - s·ª≠ d·ª•ng to√†n b·ªô k·∫øt qu·∫£ search
                    print("No tag filters - using search results only")
                    
                    # L·∫•y th√¥ng tin group_name t·ª´ MySQL
                    if search_group_ids:
                        placeholders = ','.join(['%s'] * len(search_group_ids))
                        group_name_sql = f"""
                            SELECT group_id, group_name 
                            FROM group_product 
                            WHERE group_id IN ({placeholders})
                        """
                        cursor.execute(group_name_sql, search_group_ids)
                        group_name_results = cursor.fetchall()
                        
                        combined_df = pd.DataFrame(group_name_results, columns=["group_id", "group_name"])
                        
                        # Th√™m relevance score
                        relevance_scores = {}
                        for i, group_id in enumerate(search_group_ids):
                            relevance_scores[group_id] = len(search_group_ids) - i
                        
                        combined_df['relevance_score'] = combined_df['group_id'].map(
                            lambda x: relevance_scores.get(x, 0)
                        )
                        
                        # S·∫Øp x·∫øp theo relevance score
                        combined_df = combined_df.sort_values('relevance_score', ascending=False)
            else:
                print("No search results found for specific requirements")
                # Kh√¥ng c√≥ k·∫øt qu·∫£ search, gi·ªØ nguy√™n combined_df
                if not combined_df.empty:
                    combined_df['relevance_score'] = 1.0  # ƒêi·ªÉm m·∫∑c ƒë·ªãnh
        
        # **X·ª¨ L√ù GI√Å C·∫¢** - t∆∞∆°ng t·ª± h√†m c≈©
        if min_budget or max_budget:
            if not combined_df.empty:
                group_ids_for_price = combined_df['group_id'].tolist()
                placeholders = ','.join(['%s'] * len(group_ids_for_price))
                price_sql = f"""
                    SELECT gpj.group_id, gp.group_name, gpj.default_current_price AS price
                    FROM group_product_junction gpj
                    JOIN group_product gp ON gpj.group_id = gp.group_id
                    WHERE gpj.group_id IN ({placeholders})
                    AND (gpj.group_id, gpj.default_current_price) IN (
                        SELECT group_id, MIN(default_current_price)
                        FROM group_product_junction
                        WHERE group_id IN ({placeholders})
                        GROUP BY group_id
                    )
                """
                params = group_ids_for_price + group_ids_for_price
                cursor.execute(price_sql, params)
                result = cursor.fetchall()
                prices_df = pd.DataFrame(result, columns=["group_id", "group_name", "price"])

                if not prices_df.empty:
                    combined_df = pd.merge(combined_df, prices_df, on=["group_id", "group_name"], how="inner")
                    if min_budget:
                        combined_df = combined_df[combined_df["price"] >= min_budget]
                    if max_budget and max_budget != 0:
                        combined_df = combined_df[combined_df["price"] <= max_budget]

        # Calculate ranks
        rank_columns = [col for col in combined_df.columns if col.endswith("_rank")]
        if "es_rank" in combined_df.columns:
            rank_columns.append("es_rank")
            
        if rank_columns:
            combined_df["combined_rank"] = combined_df[rank_columns].sum(axis=1)
            top_k_products = combined_df.sort_values(by="combined_rank").head(top_k)
        else:
            # N·∫øu kh√¥ng c√≥ rank columns, l·∫•y theo th·ª© t·ª±
            top_k_products = combined_df.head(top_k)
        
        # **FIX: ƒê·∫¢M B·∫¢O CURRENT_GROUP_IDS LU√îN ƒê∆Ø·ª¢C C·∫¨P NH·∫¨T**
        if not top_k_products.empty:
            current_group_ids.extend(top_k_products['group_id'].tolist())
        
        if top_k_products.empty:
            cursor.close()
            conn.close()
            brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
            return f"Kh√¥ng t√¨m th·∫•y {device}{brand_msg} ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n."

        # Build response
        brand_msg = f" c·ªßa th∆∞∆°ng hi·ªáu {brand_display}" if brand_display else ""
        
        # X√°c ƒë·ªãnh search method hi·ªÉn th·ªã
        search_method = "Tags"
        if hasattr(reqs, 'specific_requirements') and reqs.specific_requirements:
            if mongo_search_info:
                search_method = f"Tags + {mongo_search_info.get('search_method', 'MongoDB')}"
            else:
                search_method = "Tags + Elasticsearch"
        
        response = f"D∆∞·ªõi ƒë√¢y l√† top {top_k} {device}{brand_msg} ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n ({search_method}):\n"
        
        # **HI·ªÇN TH·ªä SEARCH CONDITIONS (n·∫øu c√≥)**
        if mongo_search_info and mongo_search_info.get("applied_conditions"):
            response += "\nüîç **ƒêi·ªÅu ki·ªán t√¨m ki·∫øm ƒë√£ √°p d·ª•ng:**\n"
            for condition in mongo_search_info["applied_conditions"]:
                field = condition["field"]
                operator = condition["operator"]
                value = condition["value"]
                
                # Translate field names to Vietnamese
                field_translations = {
                    "ram": "RAM",
                    "storage": "B·ªô nh·ªõ",
                    "processorModel": "Processor",
                    "processor": "Processor", 
                    "graphicCard": "Card ƒë·ªì h·ªça",
                    "rearCameraResolution": "Camera sau",
                    "frontCameraResolution": "Camera tr∆∞·ªõc",
                    "batteryCapacity": "Dung l∆∞·ª£ng pin",
                    "batteryLife": "Th·ªùi l∆∞·ª£ng pin",
                    "screenSize": "K√≠ch th∆∞·ªõc m√†n h√¨nh",
                    "refreshRate": "T·∫ßn s·ªë qu√©t",
                    "brand": "Th∆∞∆°ng hi·ªáu",
                    "productName": "T√™n s·∫£n ph·∫©m"
                }
                
                field_vn = field_translations.get(field, field)
                
                if operator in ["gte", "gt"]:
                    response += f"  ‚úì {field_vn} ‚â• {value}\n"
                elif operator in ["lte", "lt"]:
                    response += f"  ‚úì {field_vn} ‚â§ {value}\n"
                elif operator == "eq":
                    response += f"  ‚úì {field_vn} = {value}\n"
                elif operator == "regex":
                    response += f"  ‚úì {field_vn} ch·ª©a '{value}'\n"
                elif operator == "elemMatch":
                    response += f"  ‚úì {field_vn} c√≥ '{value}'\n"
                else:
                    response += f"  ‚úì {field_vn}: {value}\n"
            response += "\n"
        
        for _, product in top_k_products.iterrows():
            product_info = f"- {product['group_name']} (ID: {product['group_id']}"
            
            # Hi·ªÉn th·ªã relevance score n·∫øu c√≥
            if "relevance_score" in product and not pd.isna(product["relevance_score"]) and product["relevance_score"] > 0:
                product_info += f", relevance: {product['relevance_score']:.1f}"
            elif "combined_rank" in product and not pd.isna(product["combined_rank"]):
                product_info += f", rank: {int(product['combined_rank'])}"
                
            if "price" in product and not pd.isna(product["price"]):
                product_info += f", gi√°: {int(product['price']):,} ƒë·ªìng"
            product_info += ")"
            response += product_info + "\n"
            
        cursor.close()
        conn.close()
        return response

    except Exception as e:
        print(f"Error in product_consultation_tool_mongo: {str(e)}")
        return f"L·ªói trong qu√° tr√¨nh truy v·∫•n: {str(e)}"

def mongodb_search_specific_requirements_get_product_ids(query: str, device_type: str, top_k: int = 100) -> Dict[str, Any]:
    """
    S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch specific requirements v√† t·∫°o c√¢u truy v·∫•n MongoDB th√¥ng minh.
    
    Args:
        query: Chu·ªói t√¨m ki·∫øm (specific requirements)
        device_type: Lo·∫°i thi·∫øt b·ªã
        top_k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t·ªëi ƒëa
        
    Returns:
        Dict[str, Any]: {
            "product_ids": List[str], 
            "search_info": Dict v·ªõi th√¥ng tin v·ªÅ conditions ƒë√£ √°p d·ª•ng,
            "success": bool
        }
    """
    try:
        try:
            from all_fields_by_class import device_type_to_class, all_fields_by_class
        except ImportError:
            # Fallback mappings n·∫øu kh√¥ng t√¨m th·∫•y file
            device_type_to_class = {
                "laptop": "com.eazybytes.model.Laptop",
                "phone": "com.eazybytes.model.Phone", 
                "wireless_earphone": "com.eazybytes.model.WirelessEarphone",
                "wired_earphone": "com.eazybytes.model.WiredEarphone",
                "headphone": "com.eazybytes.model.Headphone",
                "backup_charger": "com.eazybytes.model.BackupCharger"
            }
            all_fields_by_class = {
                "laptop": [
                    # CPU v√† hi·ªáu nƒÉng
                    "processorModel", "coreCount", "threadCount", "cpuSpeed", "maxCpuSpeed",
                    # RAM
                    "ram", "ramType", "ramBusSpeed", "maxRam",
                    # Storage
                    "storage", 
                    # M√†n h√¨nh
                    "screenSize", "resolution", "refreshRate", "colorGamut", "displayTechnology",
                    # Card ƒë·ªì h·ªça
                    "graphicCard",
                    # Audio v√† k·∫øt n·ªëi
                    "audioTechnology", "ports", "wirelessConnectivity", "webcam",
                    # T√≠nh nƒÉng kh√°c
                    "otherFeatures", "keyboardBacklight",
                    # Thi·∫øt k·∫ø v√† pin
                    "size", "material", "battery", "os",
                    # Th√¥ng tin c∆° b·∫£n
                    "brand", "productName", "description"
                ],
                "phone": [
                    # C·∫•u h√¨nh c∆° b·∫£n
                    "ram", "storage", "availableStorage", "processor", "cpuSpeed", "gpu", "os",
                    # Camera
                    "rearCameraResolution", "frontCameraResolution", "rearCameraFeatures", "frontCameraFeatures", 
                    "rearVideoRecording", "rearFlash",
                    # M√†n h√¨nh
                    "screenSize", "displayTechnology", "displayResolution", "maxBrightness", "screenProtection",
                    # Pin v√† s·∫°c
                    "batteryType", "maxChargingPower", "batteryFeatures","batteryCapacity"
                    # K·∫øt n·ªëi
                    "mobileNetwork", "simType", "wifi", "bluetooth", "gps", "headphoneJack", "otherConnectivity",
                    # B·∫£o m·∫≠t v√† t√≠nh nƒÉng
                    "securityFeatures", "specialFeatures", "waterResistance",
                    # Media
                    "recording", "video", "audio",
                    # Thi·∫øt k·∫ø
                    "designType", "materials", "sizeWeight",
                    # Th√¥ng tin c∆° b·∫£n
                    "brand", "productName", "description"
                ],
                "wireless_earphone": [
                    # Pin v√† s·∫°c
                    "batteryLife", "chargingCaseBatteryLife", "chargingPort",
                    # √Çm thanh v√† k·∫øt n·ªëi
                    "audioTechnology", "connectionTechnology", "simultaneousConnections",
                    # T∆∞∆°ng th√≠ch v√† ·ª©ng d·ª•ng
                    "compatibility", "connectionApp",
                    # T√≠nh nƒÉng v√† ƒëi·ªÅu khi·ªÉn
                    "features", "controlType", "controlButtons",
                    # Th√¥ng s·ªë v·∫≠t l√Ω
                    "size",
                    # Xu·∫•t x·ª©
                    "brandOrigin", "manufactured",
                    # Th√¥ng tin c∆° b·∫£n
                    "brand", "productName", "description"
                ],
                "wired_earphone": [
                    # K·∫øt n·ªëi v√† √¢m thanh
                    "audioJack", "cableLength", "simultaneousConnections",
                    # T∆∞∆°ng th√≠ch
                    "compatibility",
                    # T√≠nh nƒÉng v√† ƒëi·ªÅu khi·ªÉn
                    "features", "controlType", "controlButtons",
                    # Th√¥ng s·ªë v·∫≠t l√Ω
                    "weight",
                    # Xu·∫•t x·ª©
                    "brandOrigin", "manufactured",
                    # Th√¥ng tin c∆° b·∫£n
                    "brand", "productName", "description"
                ],
                "headphone": [
                    # Pin v√† s·∫°c
                    "batteryLife", "chargingPort",
                    # K·∫øt n·ªëi v√† √¢m thanh
                    "audioJack", "connectionTechnology", "simultaneousConnections",
                    # T∆∞∆°ng th√≠ch
                    "compatibility",
                    # T√≠nh nƒÉng v√† ƒëi·ªÅu khi·ªÉn
                    "features", "controlType", "controlButtons",
                    # Th√¥ng s·ªë v·∫≠t l√Ω
                    "size", "weight",
                    # Xu·∫•t x·ª©
                    "brandOrigin", "manufactured",
                    # Th√¥ng tin c∆° b·∫£n
                    "brand", "productName", "description"
                ],
                "backup_charger": [
                    # Pin v√† c√¥ng su·∫•t
                    "batteryCapacity", "batteryCellType",
                    # S·∫°c v√† k·∫øt n·ªëi
                    "input", "output", "chargingTime",
                    # T√≠nh nƒÉng c√¥ng ngh·ªá
                    "technologyFeatures",
                    # Th√¥ng s·ªë v·∫≠t l√Ω
                    "size", "weight",
                    # Xu·∫•t x·ª©
                    "brandOrigin", "manufactured",
                    # Th√¥ng tin c∆° b·∫£n
                    "brand", "productName", "description"
                ]
            }
        
        # **B∆Ø·ªöC 1: S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch specific requirements**
        device_fields = all_fields_by_class.get(device_type.lower(), [])
        
        llm_prompt = f"""
Ph√¢n t√≠ch specific requirements v√† t·∫°o MongoDB query cho {device_type}.

SPECIFIC REQUIREMENTS: "{query}"

C√°c fields c√≥ s·∫µn cho {device_type}: {device_fields}

FIELD TYPES FOR {device_type.upper()}:

LAPTOP FIELDS:
- Numeric: ram, maxRam, ramBusSpeed, coreCount, threadCount, refreshRate, battery, cpuSpeed, maxCpuSpeed
- String: processorModel, ramType, screenSize, resolution, graphicCard, webcam, keyboardBacklight, size, material, os, brand, productName, description
- Arrays: storage, colorGamut, displayTechnology, audioTechnology, ports, wirelessConnectivity, otherFeatures, touchScreen

PHONE FIELDS:
- Numeric: ram, storage, availableStorage, maxBrightness, maxChargingPower, batteryCapacity
- String: processor, cpuSpeed, gpu, os, displayTechnology, displayResolution, screenSize, batteryType, mobileNetwork, simType, headphoneJack, waterResistance, designType, materials, sizeWeight, rearCameraResolution, frontCameraResolution, rearFlash, contactLimit, screenProtection, chargingPort, brand, productName, description
- Arrays: rearCameraFeatures, frontCameraFeatures, rearVideoRecording, batteryFeatures, securityFeatures, specialFeatures, recording, video, audio, wifi, bluetooth, gps, otherConnectivity

WIRELESS_EARPHONE FIELDS:
- Numeric: batteryLife, chargingCaseBatteryLife, weight (extracted from text values)
- String: simultaneousConnections, size, brandOrigin, manufactured, brand, productName, description
- Arrays: chargingPort, audioTechnology, compatibility, connectionApp, features, connectionTechnology, controlType, controlButtons

BACKUP_CHARGER FIELDS:
- Numeric: batteryCapacity, weight (extracted from capacity and weight values)
- String: chargingEfficiency, batteryCellType, size, brandOrigin, manufactured, brand, productName, description
- Arrays: input, output, chargingTime, technologyFeatures

HEADPHONE FIELDS:
- Numeric: weight (extracted from text values)
- String: batteryLife, chargingPort, audioJack, cableLength, simultaneousConnections, size, brandOrigin, manufactured, connectionApp, brand, productName, description
- Arrays: connectionTechnology, compatibility, features, controlType, controlButtons, audioTechnology

WIRED_EARPHONE FIELDS:
- Numeric: weight
- String: audioJack, cableLength, simultaneousConnections, brandOrigin, manufactured, brand, productName, description
- Arrays: audioTechnology, compatibility, features, controlType, controlButtons

Tr·∫£ v·ªÅ JSON:
{{
    "conditions": [
        {{
            "field": "field_name",
            "operator": "eq|gte|lte|gt|lt|regex|in|elemMatch|max|min",
            "value": "search_value",
            "type": "string|number|array",
            "is_array": true/false
        }}
    ],
    "sort_fields": [
        {{
            "field": "field_name",
            "order": "desc|asc",
            "priority": 1
        }}
    ],
    "text_search_fields": ["field1", "field2"],
    "text_search_keywords": ["keyword1", "keyword2"]
}}

Rules:
1. **NUMERIC FIELDS** (d√πng numeric operators: gte, lte, gt, lt):
   - RAM: "8GB", "16GB" ‚Üí value: 8, 16
   - Storage/Dung l∆∞·ª£ng: "512GB", "1TB" ‚Üí value: 512, 1024
   - CPU Speed: "2.4GHz", "3.2GHz" ‚Üí value: 2.4, 3.2
   - Battery/Pin: "4000mAh", "5000mAh" ‚Üí value: 4000, 5000
   - Camera: "48MP", "108MP" ‚Üí value: 48, 108
   - Screen size: "6.1 inch", "15.6 inch" ‚Üí value: 6.1, 15.6

2. **STRING FIELDS** (d√πng regex):
   - Processor/Chip: "Snapdragon 8 Gen 2", "Intel i7", "Ryzen 5"
   - GPU/Card ƒë·ªì h·ªça: "RTX 4070", "GTX 1650", "Adreno 740"
   - OS: "Windows 11", "Android 13", "iOS 16"
   - Brand: "Apple", "Samsung", "Dell"

3. **ARRAY FIELDS** (d√πng elemMatch ho·∫∑c in):
   - Features/T√≠nh nƒÉng: "OIS", "5G", "Face ID", "Wireless charging"
   - Connectivity: "Wi-Fi 6", "Bluetooth 5.3", "USB-C", "Lightning"
   - Display tech: "OLED", "IPS", "AMOLED", "Retina"
   - Audio tech: "Dolby Atmos", "DTS:X", "Hi-Res Audio"

4. **PH√ÇN BI·ªÜT TO√ÅN T·ª¨ SO S√ÅNH CH√çNH X√ÅC:**
   - "l·ªõn h∆°n X", "tr√™n X", "h∆°n X", "cao h∆°n X" ‚Üí operator: "gt" (strictly greater than)
   - "t·ª´ X tr·ªü l√™n", "√≠t nh·∫•t X", "X tr·ªü l√™n", "t·ªëi thi·ªÉu X" ‚Üí operator: "gte" (greater than or equal)
   - "nh·ªè h∆°n X", "d∆∞·ªõi X", "th·∫•p h∆°n X", "√≠t h∆°n X" ‚Üí operator: "lt" (strictly less than)  
   - "t·ªëi ƒëa X", "kh√¥ng qu√° X", "X tr·ªü xu·ªëng", "nhi·ªÅu nh·∫•t X" ‚Üí operator: "lte" (less than or equal)
   - "b·∫±ng X", "ƒë√∫ng X", "ch√≠nh x√°c X" ‚Üí operator: "eq" (equal)

5. **X·ª¨ L√ù MIN/MAX**:
   - "cao nh·∫•t", "t·ªët nh·∫•t", "m·∫°nh nh·∫•t" ‚Üí sort order: "desc"
   - "th·∫•p nh·∫•t", "r·∫ª nh·∫•t", "nh·∫π nh·∫•t" ‚Üí sort order: "asc"
   - Kh√¥ng c·∫ßn conditions cho min/max, ch·ªâ c·∫ßn sort_fields

6. **KEYWORDS QUAN TR·ªåNG**:
   - text_search_keywords: c√°c t·ª´ kh√≥a quan tr·ªçng ƒë·ªÉ t√¨m ki·∫øm full-text
   - text_search_fields: th∆∞·ªùng l√† ["productName", "description"] + related fields

V√≠ d·ª• laptop:
Input: "laptop gaming RAM 16GB RTX 4070 SSD 1TB"
Output: {{
    "conditions": [
        {{"field": "ram", "operator": "gte", "value": "16", "type": "number", "is_array": false}},
        {{"field": "graphicCard", "operator": "regex", "value": "RTX 4070", "type": "string", "is_array": false}},
        {{"field": "storage", "operator": "elemMatch", "value": "1TB SSD", "type": "string", "is_array": true}}
    ],
    "sort_fields": [],
    "text_search_fields": ["productName", "description", "graphicCard"],
    "text_search_keywords": ["gaming", "16GB", "RTX", "4070", "1TB", "SSD"]
}}

Input: "laptop pin cao nh·∫•t"
Output: {{
    "conditions": [],
    "sort_fields": [
        {{"field": "battery", "order": "desc", "priority": 1}}
    ],
    "text_search_fields": ["productName", "description"],
    "text_search_keywords": ["pin", "cao nh·∫•t", "battery"]
}}

V√≠ d·ª• phone:
Input: "ƒëi·ªán tho·∫°i camera 108MP chip Snapdragon pin 5000mAh"
Output: {{
    "conditions": [
        {{"field": "rearCameraResolution", "operator": "gte", "value": "108", "type": "number", "is_array": false}},
        {{"field": "processor", "operator": "regex", "value": "Snapdragon", "type": "string", "is_array": false}},
        {{"field": "batteryCapacity", "operator": "gte", "value": "5000", "type": "number", "is_array": false}}
    ],
    "sort_fields": [],
    "text_search_fields": ["productName", "description", "processor"],
    "text_search_keywords": ["108MP", "Snapdragon", "5000mAh", "camera", "chip", "pin"]
}}

Input: "ƒëi·ªán tho·∫°i pin l·ªõn h∆°n 6000 mAh"
Output: {{
    "conditions": [
        {{"field": "batteryCapacity", "operator": "gt", "value": "6000", "type": "number", "is_array": false}}
    ],
    "sort_fields": [],
    "text_search_fields": ["productName", "description"],
    "text_search_keywords": ["pin", "l·ªõn h∆°n", "6000", "mAh"]
}}

Input: "ƒëi·ªán tho·∫°i m√†n h√¨nh l·ªõn nh·∫•t"
Output: {{
    "conditions": [],
    "sort_fields": [
        {{"field": "screenSize", "order": "desc", "priority": 1}}
    ],
    "text_search_fields": ["productName", "screenSize"],
    "text_search_keywords": ["m√†n h√¨nh", "l·ªõn nh·∫•t", "screen"]
}}

V√≠ d·ª• wireless_earphone:
Input: "tai nghe kh√¥ng d√¢y pin 8 gi·ªù ch·ªëng n∆∞·ªõc Bluetooth 5.3"
Output: {{
    "conditions": [
        {{"field": "batteryLife", "operator": "gte", "value": "8", "type": "number", "is_array": false}},
        {{"field": "features", "operator": "elemMatch", "value": "ch·ªëng n∆∞·ªõc", "type": "string", "is_array": true}},
        {{"field": "connectionTechnology", "operator": "elemMatch", "value": "Bluetooth 5.3", "type": "string", "is_array": true}}
    ],
    "sort_fields": [],
    "text_search_fields": ["productName", "description"],
    "text_search_keywords": ["kh√¥ng d√¢y", "8 gi·ªù", "ch·ªëng n∆∞·ªõc", "Bluetooth", "5.3"]
}}

V√≠ d·ª• backup_charger:
Input: "s·∫°c d·ª± ph√≤ng 20000mAh s·∫°c nhanh PD USB-C"
Output: {{
    "conditions": [
        {{"field": "batteryCapacity", "operator": "gte", "value": "20000", "type": "number", "is_array": false}},
        {{"field": "technologyFeatures", "operator": "elemMatch", "value": "s·∫°c nhanh", "type": "string", "is_array": true}},
        {{"field": "technologyFeatures", "operator": "elemMatch", "value": "PD", "type": "string", "is_array": true}},
        {{"field": "output", "operator": "elemMatch", "value": "USB-C", "type": "string", "is_array": true}}
    ],
    "sort_fields": [],
    "text_search_fields": ["productName", "description"],
    "text_search_keywords": ["20000mAh", "s·∫°c nhanh", "PD", "USB-C"]
}}

V√≠ d·ª• headphone:
Input: "tai nghe ch·ª•p tai pin 50 gi·ªù c√≥ mic noise cancelling"
Output: {{
    "conditions": [
        {{"field": "batteryLife", "operator": "regex", "value": "50", "type": "string", "is_array": false}},
        {{"field": "features", "operator": "elemMatch", "value": "mic", "type": "string", "is_array": true}},
        {{"field": "features", "operator": "elemMatch", "value": "noise cancelling", "type": "string", "is_array": true}}
    ],
    "sort_fields": [],
    "text_search_fields": ["productName", "description"],
    "text_search_keywords": ["ch·ª•p tai", "50 gi·ªù", "mic", "noise cancelling"]
}}

V√≠ d·ª• wired_earphone:
Input: "tai nghe c√≥ d√¢y jack 3.5mm c√≥ mic t∆∞∆°ng th√≠ch ƒëi·ªán tho·∫°i"
Output: {{
    "conditions": [
        {{"field": "audioJack", "operator": "regex", "value": "3.5mm", "type": "string", "is_array": false}},
        {{"field": "features", "operator": "elemMatch", "value": "mic", "type": "string", "is_array": true}},
        {{"field": "compatibility", "operator": "elemMatch", "value": "ƒëi·ªán tho·∫°i", "type": "string", "is_array": true}}
    ],
    "sort_fields": [],
    "text_search_fields": ["productName", "description"],
    "text_search_keywords": ["c√≥ d√¢y", "3.5mm", "mic", "t∆∞∆°ng th√≠ch"]
}}

CH·ªà TR·∫¢ V·ªÄ JSON, KH√îNG GI·∫¢I TH√çCH.
"""

        print(f"LLM analyzing specific requirements: {query}")
        llm_response = llm.complete(llm_prompt)
        print("LLM response:",llm_response)
        # Parse LLM response
        import json
        import re
        
        response_text = llm_response.text.strip()
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if not json_match:
            print("LLM response invalid, falling back to keyword search")
            return mongodb_search_fallback_keywords(query, device_type, top_k)
        
        try:
            llm_analysis = json.loads(json_match.group())
        except json.JSONDecodeError as e:
            print(f"JSON parse error: {e}, falling back to keyword search")
            return mongodb_search_fallback_keywords(query, device_type, top_k)
        
        print(f"LLM analysis: {llm_analysis}")
        
        # **B∆Ø·ªöC 2: K·∫øt n·ªëi MongoDB**
        db = mongodb.connect()
        if db is None:
            print("Cannot connect to MongoDB")
            return []
        
        collection = mongodb.get_collection("baseProduct")
        if collection is None:
            print("Cannot find baseProduct collection")
            return []
        
        # **B∆Ø·ªöC 3: X√¢y d·ª±ng MongoDB query t·ª´ LLM analysis**
        base_filter = {}
        if device_type in device_type_to_class:
            base_filter["_class"] = device_type_to_class[device_type]
        
        # X·ª≠ l√Ω conditions t·ª´ LLM
        match_conditions = [base_filter] if base_filter else []
        applied_conditions = []  # Track applied conditions for user display
        
        for condition in llm_analysis.get("conditions", []):
            field = condition.get("field")
            operator = condition.get("operator")
            value = condition.get("value")
            value_type = condition.get("type", "string")
            is_array = condition.get("is_array", False)
            
            if not all([field, operator, value]):
                continue
            
            # Convert value type
            original_value = value  # Keep original for display
            if value_type == "number":
                try:
                    if isinstance(value, str):
                        numbers = re.findall(r'(\d+(?:\.\d+)?)', str(value))
                        if numbers:
                            value = float(numbers[0])
                        else:
                            continue
                    else:
                        value = float(value)
                except (ValueError, TypeError):
                    continue
            
            # Track applied condition for display
            condition_desc = {
                "field": field,
                "operator": operator,
                "value": original_value,
                "type": value_type,
                "is_array": is_array
            }
            applied_conditions.append(condition_desc)
            
            # X√¢y d·ª±ng MongoDB condition
            if operator == "elemMatch":
                # X·ª≠ l√Ω array fields v·ªõi $elemMatch
                if is_array:
                    match_conditions.append({
                        field: {
                            "$elemMatch": {
                                "$regex": str(value),
                                "$options": "i"
                            }
                        }
                    })
                else:
                    # Fallback cho non-array
                    match_conditions.append({field: {"$regex": str(value), "$options": "i"}})
                    
            elif operator == "eq":
                if is_array:
                    # Cho array fields, t√¨m element ch·ª©a gi√° tr·ªã
                    match_conditions.append({field: {"$elemMatch": {"$regex": str(value), "$options": "i"}}})
                elif value_type == "number":
                    match_conditions.append({
                        "$expr": {
                            "$eq": [
                                {
                                    "$convert": {
                                        "input": {
                                            "$arrayElemAt": [
                                                {
                                                    "$map": {
                                                        "input": {"$regexFindAll": {"input": f"${field}", "regex": r"(\d+(?:\.\d+)?)"}},
                                                        "as": "match",
                                                        "in": "$$match.match"
                                                    }
                                                },
                                                0
                                            ]
                                        },
                                        "to": "double",
                                        "onError": 0
                                    }
                                },
                                value
                            ]
                        }
                    })
                else:
                    match_conditions.append({field: {"$regex": f"^{re.escape(str(value))}$", "$options": "i"}})
                    
            elif operator in ["gte", "gt", "lte", "lt"]:
                if is_array:
                    # Array fields kh√¥ng support numeric comparison tr·ª±c ti·∫øp
                    match_conditions.append({field: {"$elemMatch": {"$regex": str(value), "$options": "i"}}})
                elif value_type == "number":
                    comparison_op = f"${operator}"
                    match_conditions.append({
                        "$expr": {
                            comparison_op: [
                                {
                                    "$convert": {
                                        "input": {
                                            "$arrayElemAt": [
                                                {
                                                    "$map": {
                                                        "input": {"$regexFindAll": {"input": f"${field}", "regex": r"(\d+(?:\.\d+)?)"}},
                                                        "as": "match",
                                                        "in": "$$match.match"
                                                    }
                                                },
                                                0
                                            ]
                                        },
                                        "to": "double",
                                        "onError": 0
                                    }
                                },
                                value
                            ]
                        }
                    })
                else:
                    match_conditions.append({field: {f"${operator}": value}})
                    
            elif operator == "regex":
                if is_array:
                    match_conditions.append({field: {"$elemMatch": {"$regex": str(value), "$options": "i"}}})
                else:
                    match_conditions.append({field: {"$regex": str(value), "$options": "i"}})
                
            elif operator == "in":
                values_list = value if isinstance(value, list) else [value]
                if is_array:
                    # Cho array fields, t√¨m element n√†o ƒë√≥ trong array ch·ª©a m·ªôt trong c√°c values
                    array_conditions = []
                    for val in values_list:
                        array_conditions.append({field: {"$elemMatch": {"$regex": str(val), "$options": "i"}}})
                    if len(array_conditions) == 1:
                        match_conditions.append(array_conditions[0])
                    else:
                        match_conditions.append({"$or": array_conditions})
                else:
                    match_conditions.append({field: {"$in": values_list}})
        
        # **B∆Ø·ªöC 4: X√¢y d·ª±ng MongoDB aggregation pipeline**
        pipeline_stages = []
        
        # Match stage v·ªõi conditions
        field_conditions_count = len(match_conditions) - (1 if base_filter else 0)
        
        if field_conditions_count > 0:
            if len(match_conditions) == 1:
                match_stage = match_conditions[0]
            else:
                match_stage = {"$and": match_conditions}
            pipeline_stages.append({"$match": match_stage})
            print(f"Added match stage: {match_stage}")
        
        # Sort stage v·ªõi sort_fields t·ª´ LLM
        sort_fields = llm_analysis.get("sort_fields", [])
        if sort_fields:
            sort_spec = {}
            # Sort theo priority
            sorted_fields = sorted(sort_fields, key=lambda x: x.get("priority", 999))
            for sort_field in sorted_fields:
                field_name = sort_field.get("field")
                order = sort_field.get("order", "desc")
                if field_name:
                    sort_spec[field_name] = -1 if order == "desc" else 1
            
            if sort_spec:
                pipeline_stages.append({"$sort": sort_spec})
                print(f"Added sort stage: {sort_spec}")
        
        # Limit stage
        pipeline_stages.append({"$limit": top_k})
        
        # Th·ª±c hi·ªán aggregation pipeline
        if pipeline_stages:
            print(f"MongoDB aggregation pipeline: {pipeline_stages}")
            results = list(collection.aggregate(pipeline_stages))
        else:
            # Fallback to simple find
            results = list(collection.find(base_filter, {"_id": 1}).limit(top_k))
        
        product_ids = [str(doc['_id']) for doc in results]
        print(f"Pipeline search found {len(product_ids)} product_ids")
        
        # N·∫øu c√≥ k·∫øt qu·∫£ t·ª´ pipeline, return lu√¥n
        if product_ids:
            search_method = "MongoDB Field Conditions"
            if sort_fields:
                search_method += " + Sort"
                
            search_info = {
                "search_method": search_method,
                "applied_conditions": applied_conditions,
                "sort_fields": sort_fields,
                "results_count": len(product_ids),
                "query_used": query,
                "device_type": device_type,
                "mongodb_pipeline": pipeline_stages
            }
            
            return {
                "product_ids": product_ids,
                "search_info": search_info,
                "success": True
            }
        
        # **B∆Ø·ªöC 5: N·∫øu field conditions kh√¥ng t√¨m ƒë∆∞·ª£c, th√™m text search**
        print("Step 2 - Field conditions found no results, trying with text search...")
        
        text_search_keywords = llm_analysis.get("text_search_keywords", [])
        text_search_fields = llm_analysis.get("text_search_fields", ["productName", "description"])
        
        if text_search_keywords:
            # T·∫°o text search conditions
            text_conditions = []
            for keyword in text_search_keywords:
                keyword_conditions = []
                for field in text_search_fields:
                    keyword_conditions.append({field: {"$regex": keyword, "$options": "i"}})
                if keyword_conditions:
                    text_conditions.append({"$or": keyword_conditions})
            
            # Th√™m text conditions v√†o match_conditions
            if text_conditions:
                # Ch·ªâ th√™m 1-2 text conditions quan tr·ªçng nh·∫•t
                for i, text_condition in enumerate(text_conditions[:2]):
                    match_conditions.append(text_condition)
        
        # **B∆Ø·ªöC 6: X√¢y d·ª±ng final filter v·ªõi text search**
        if len(match_conditions) == 1:
            final_filter = match_conditions[0]
        else:
            final_filter = {"$and": match_conditions}
        
        print(f"Step 2 - Field + Text MongoDB filter: {final_filter}")
        
        # **B∆Ø·ªöC 7: Th·ª±c hi·ªán search v·ªõi text search**
        results = list(collection.find(final_filter, {"_id": 1}).limit(top_k))
        
        # Extract product_ids
        product_ids = [str(doc['_id']) for doc in results]
        
        print(f"Field + Text search found {len(product_ids)} product_ids")
        
        search_info = {
            "search_method": "MongoDB Field + Text Search",
            "applied_conditions": applied_conditions,
            "text_search_keywords": llm_analysis.get("text_search_keywords", []),
            "results_count": len(product_ids),
            "query_used": query,
            "device_type": device_type,
            "mongodb_filter": final_filter
        }
        
        return {
            "product_ids": product_ids,
            "search_info": search_info,
            "success": len(product_ids) > 0
        }
        
    except Exception as e:
        print(f"Error in LLM MongoDB search: {str(e)}")
        print("Falling back to keyword search")
        fallback_result = mongodb_search_fallback_keywords(query, device_type, top_k)
        return {
            "product_ids": fallback_result,
            "search_info": {
                "search_method": "MongoDB Fallback Keywords",
                "error": str(e),
                "results_count": len(fallback_result),
                "query_used": query,
                "device_type": device_type
            },
            "success": len(fallback_result) > 0
        }
    finally:
        mongodb.disconnect()

def mongodb_search_fallback_keywords(query: str, device_type: str, top_k: int = 100) -> List[str]:
    """
    Fallback function s·ª≠ d·ª•ng keyword search ƒë∆°n gi·∫£n khi LLM fails.
    """
    try:
        try:
            from all_fields_by_class import device_type_to_class
        except ImportError:
            device_type_to_class = {
                "laptop": "com.eazybytes.model.Laptop",
                "phone": "com.eazybytes.model.Phone", 
                "wireless_earphone": "com.eazybytes.model.WirelessEarphone",
                "wired_earphone": "com.eazybytes.model.WiredEarphone",
                "headphone": "com.eazybytes.model.Headphone",
                "backup_charger": "com.eazybytes.model.BackupCharger"
            }
        
        db = mongodb.connect()
        if db is None:
            return []
        
        collection = mongodb.get_collection("baseProduct")
        if collection is None:
            return []
        
        # Base filter
        base_filter = {}
        if device_type in device_type_to_class:
            base_filter["_class"] = device_type_to_class[device_type]
        
        # Simple keyword search
        keywords = query.lower().split()
        search_fields = ["productName", "brand", "description"]
        
        regex_conditions = []
        for keyword in keywords:
            keyword_conditions = []
            for field in search_fields:
                keyword_conditions.append({field: {"$regex": keyword, "$options": "i"}})
            if keyword_conditions:
                regex_conditions.append({"$or": keyword_conditions})
        
        if regex_conditions:
            final_filter = {"$and": [base_filter] + regex_conditions}
        else:
            final_filter = base_filter
        
        results = list(collection.find(final_filter, {"_id": 1}).limit(top_k))
        product_ids = [str(doc['_id']) for doc in results]
        
        print(f"Fallback search found {len(product_ids)} product_ids")
        return product_ids
        
    except Exception as e:
        print(f"Error in fallback search: {str(e)}")
        return []
    finally:
        mongodb.disconnect()



def debug_mongodb_field_data(device_type: str = "phone", field_name: str = "frontCameraResolution", limit: int = 10) -> str:
    """
    Debug function ƒë·ªÉ ki·ªÉm tra data trong MongoDB field v√† test regex extraction.
    
    Args:
        device_type: Lo·∫°i thi·∫øt b·ªã ƒë·ªÉ test
        field_name: Field name ƒë·ªÉ ki·ªÉm tra
        limit: S·ªë l∆∞·ª£ng sample records
        
    Returns:
        str: Debug information
    """
    try:
        from all_fields_by_class import device_type_to_class
    except ImportError:
        device_type_to_class = {
            "laptop": "com.eazybytes.model.Laptop",
            "phone": "com.eazybytes.model.Phone", 
            "wireless_earphone": "com.eazybytes.model.WirelessEarphone",
            "wired_earphone": "com.eazybytes.model.WiredEarphone",
            "headphone": "com.eazybytes.model.Headphone",
            "backup_charger": "com.eazybytes.model.BackupCharger"
        }
    
    try:
        # K·∫øt n·ªëi MongoDB
        db = mongodb.connect()
        if db is None:
            return "‚ùå Cannot connect to MongoDB"
        
        collection = mongodb.get_collection("baseProduct")
        if collection is None:
            return "‚ùå Cannot find baseProduct collection"
        
        # Base filter
        base_filter = {}
        if device_type in device_type_to_class:
            base_filter["_class"] = device_type_to_class[device_type]
        
        # L·∫•y sample data
        projection = {field_name: 1, "productName": 1, "brand": 1, "_id": 1}
        sample_docs = list(collection.find(base_filter, projection).limit(limit))
        
        output = []
        output.append(f"=== DEBUG MongoDB Field: {field_name} (Device: {device_type}) ===")
        output.append(f"Base filter: {base_filter}")
        output.append(f"Found {len(sample_docs)} sample documents")
        output.append("")
        
        # Analyze sample data
        field_values = []
        for i, doc in enumerate(sample_docs, 1):
            product_name = doc.get('productName', 'N/A')
            brand = doc.get('brand', 'N/A')
            field_value = doc.get(field_name, 'N/A')
            doc_id = str(doc.get('_id', 'N/A'))
            
            output.append(f"{i}. Product: {product_name} - {brand}")
            output.append(f"   {field_name}: \"{field_value}\"")
            output.append(f"   _id: {doc_id}")
            
            if field_value != 'N/A':
                field_values.append(str(field_value))
            
            output.append("")
        
        # Test regex extraction
        output.append("=== REGEX EXTRACTION ANALYSIS ===")
        import re
        
        unique_values = list(set(field_values))[:10]  # Test max 10 unique values
        output.append(f"Testing {len(unique_values)} unique field values:")
        output.append("")
        
        extraction_success = 0
        for val in unique_values:
            numbers = re.findall(r'(\d+(?:\.\d+)?)', str(val))
            if numbers:
                extracted = float(numbers[0])
                output.append(f"‚úì \"{val}\" ‚Üí {extracted}")
                extraction_success += 1
            else:
                output.append(f"‚úó \"{val}\" ‚Üí No number found")
        
        output.append("")
        output.append("=== MONGODB QUERY TEST ===")
        
        # Test query v·ªõi value = 12
        test_value = 12.0
        mongo_filter = {
            "$and": [
                base_filter,
                {
                    "$expr": {
                        "$gte": [
                            {
                                "$convert": {
                                    "input": {
                                        "$arrayElemAt": [
                                            {
                                                "$map": {
                                                    "input": {"$regexFindAll": {"input": f"${field_name}", "regex": r"(\d+(?:\.\d+)?)"}},
                                                    "as": "match",
                                                    "in": "$$match.match"
                                                }
                                            },
                                            0
                                        ]
                                    },
                                    "to": "double",
                                    "onError": 0
                                }
                            },
                            test_value
                        ]
                    }
                }
            ]
        }
        
        output.append(f"Testing MongoDB query for {field_name} >= {test_value}")
        output.append("Query filter:")
        output.append(str(mongo_filter))
        
        query_results = list(collection.find(mongo_filter, projection).limit(5))
        output.append(f"Query results: {len(query_results)} documents found")
        
        for i, doc in enumerate(query_results, 1):
            product_name = doc.get('productName', 'N/A')
            field_value = doc.get(field_name, 'N/A')
            output.append(f"  {i}. {product_name}: {field_value}")
        
        return "\n".join(output)
        
    except Exception as e:
        return f"‚ùå Error in debug: {str(e)}\n{traceback.format_exc()}"
    finally:
        mongodb.disconnect()

def handle_superlative_query(query: str, device_type: str, top_k: int = 5) -> str:
    """
    X·ª≠ l√Ω c√°c query t√¨m ki·∫øm "l·ªõn nh·∫•t", "cao nh·∫•t", "t·ªëi ƒëa" v·ªõi unit validation.
    
    Args:
        query: Query ch·ª©a t·ª´ kh√≥a superlative
        device_type: Lo·∫°i thi·∫øt b·ªã
        top_k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£
        
    Returns:
        str: K·∫øt qu·∫£ t√¨m ki·∫øm theo ti√™u ch√≠ "l·ªõn nh·∫•t"
    """
    try:
        from all_fields_by_class import device_type_to_class
    except ImportError:
        device_type_to_class = {
            "laptop": "com.eazybytes.model.Laptop",
            "phone": "com.eazybytes.model.Phone", 
            "wireless_earphone": "com.eazybytes.model.WirelessEarphone",
            "wired_earphone": "com.eazybytes.model.WiredEarphone",
            "headphone": "com.eazybytes.model.Headphone",
            "backup_charger": "com.eazybytes.model.BackupCharger"
        }
    
    try:
        # Import config functions
        from tools.superlative_fields_config import (
            find_superlative_field_by_keywords,
            get_default_superlative_field,
            validate_field_value_has_unit,
            get_superlative_field_config
        )
        
        # **B∆Ø·ªöC 1: T√¨m field c·∫ßn t√¨m max d·ª±a tr√™n config**
        target_field, field_config = find_superlative_field_by_keywords(device_type, query)
        
        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c field c·ª• th·ªÉ, d√πng field m·∫∑c ƒë·ªãnh
        if not target_field or not field_config:
            target_field, field_config = get_default_superlative_field(device_type)
            print(f"Using default field: {target_field}")
        
        if not target_field or not field_config:
            return f"Kh√¥ng th·ªÉ x√°c ƒë·ªãnh tr∆∞·ªùng t√¨m ki·∫øm 'l·ªõn nh·∫•t' cho {device_type}."
        
        field_name_vn = field_config.get("name_vn", target_field)
        required_units = field_config.get("required_units", [])
        unit_regex = field_config.get("unit_regex", "")
        sort_order = field_config.get("sort_order", "desc")
        
        print(f"Superlative search: {device_type} with max {target_field} ({field_name_vn})")
        print(f"Required units: {required_units}")
        print(f"Unit regex: {unit_regex}")
        
        # **B∆Ø·ªöC 2: MongoDB aggregation ƒë·ªÉ t√¨m max values v·ªõi unit validation**
        db = mongodb.connect()
        if db is None:
            return "Kh√¥ng th·ªÉ k·∫øt n·ªëi MongoDB ƒë·ªÉ t√¨m gi√° tr·ªã l·ªõn nh·∫•t."
        
        collection = mongodb.get_collection("baseProduct")
        if collection is None:
            return "Kh√¥ng t√¨m th·∫•y collection baseProduct."
        
        # Base filter
        base_filter = {}
        if device_type in device_type_to_class:
            base_filter["_class"] = device_type_to_class[device_type]
        
        # **B∆Ø·ªöC 3: Aggregation pipeline v·ªõi unit validation**
        pipeline = [
            {"$match": base_filter},
            {
                "$addFields": {
                    "field_value": f"${target_field}",
                    "has_valid_unit": {
                        "$cond": [
                            {"$ne": [f"${target_field}", None]},
                            {
                                "$cond": [
                                    {"$regexMatch": {"input": f"${target_field}", "regex": unit_regex, "options": "i"}},
                                    True,
                                    False
                                ]
                            },
                            False
                        ]
                    } if unit_regex else True,
                    "numeric_value": {
                        "$convert": {
                            "input": {
                                "$arrayElemAt": [
                                    {
                                        "$map": {
                                            "input": {"$regexFindAll": {"input": f"${target_field}", "regex": r"(\d+(?:\.\d+)?)"}},
                                            "as": "match",
                                            "in": "$$match.match"
                                        }
                                    },
                                    0
                                ]
                            },
                            "to": "double",
                            "onError": 0
                        }
                    }
                }
            },
            {
                "$match": {
                    "has_valid_unit": True,
                    "numeric_value": {"$gt": 0}
                }
            },
            {"$sort": {"numeric_value": -1 if sort_order == "desc" else 1}},
            {"$limit": top_k * 3},  # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ ƒë·ªß sau khi convert
            {
                "$project": {
                    "_id": 1, 
                    "productName": 1, 
                    "brand": 1, 
                    target_field: 1, 
                    "field_value": 1,
                    "numeric_value": 1,
                    "has_valid_unit": 1
                }
            }
        ]
        
        print(f"MongoDB aggregation pipeline: {pipeline}")
        results = list(collection.aggregate(pipeline))
        
        if not results:
            return f"Kh√¥ng t√¨m th·∫•y {device_type} n√†o c√≥ {field_name_vn} h·ª£p l·ªá v·ªõi ƒë∆°n v·ªã {required_units}."
        
        print(f"MongoDB found {len(results)} products with valid units")
        
        # **B∆Ø·ªöC 4: Log m·ªôt v√†i k·∫øt qu·∫£ ƒë·ªÉ debug**
        print("Sample results:")
        for i, result in enumerate(results[:3]):
            print(f"  {i+1}. {result.get('productName', 'N/A')}: {result.get('field_value', 'N/A')} (numeric: {result.get('numeric_value', 0)}, valid_unit: {result.get('has_valid_unit', False)})")
        
        # **B∆Ø·ªöC 5: Convert product_ids to group_ids**
        max_group_ids = []
        max_info = []
        
        for result in results:
            if len(max_group_ids) >= top_k:
                break
                
            product_id = str(result['_id'])
            mysql_result = find_group_id_by_product_id(product_id)
            
            if mysql_result.get("status") == "success":
                group_id = mysql_result.get("group_id")
                if group_id and group_id not in max_group_ids:
                    max_group_ids.append(group_id)
                    max_info.append({
                        "group_id": group_id,
                        "product_name": result.get('productName', 'N/A'),
                        "brand": result.get('brand', 'N/A'),
                        "field_value": result.get('field_value', 'N/A'),
                        "numeric_value": result.get('numeric_value', 0),
                        "has_valid_unit": result.get('has_valid_unit', False)
                    })
        
        if not max_group_ids:
            return f"Kh√¥ng t√¨m th·∫•y mapping MySQL cho {device_type} c√≥ {field_name_vn} l·ªõn nh·∫•t."
        
        # **B∆Ø·ªöC 6: Get detailed info from MySQL**
        conn = mysql.connect()
        cursor = conn.cursor()
        
        placeholders = ','.join(['%s'] * len(max_group_ids))
        detail_sql = f"""
            SELECT 
                gp.group_id, 
                gp.group_name, 
                gp.brand,
                gp.type,
                MIN(gpj.default_current_price) AS min_price,
                GROUP_CONCAT(DISTINCT t.tag_name ORDER BY t.tag_name) AS tags
            FROM group_product gp
            LEFT JOIN group_product_junction gpj ON gp.group_id = gpj.group_id
            LEFT JOIN group_tags gt ON gp.group_id = gt.group_id
            LEFT JOIN tags t ON gt.tag_id = t.tag_id
            WHERE gp.group_id IN ({placeholders}) AND gp.type = %s
            GROUP BY gp.group_id, gp.group_name, gp.brand, gp.type
            ORDER BY FIELD(gp.group_id, {placeholders})
        """
        
        params = max_group_ids + [device_type] + max_group_ids
        cursor.execute(detail_sql, params)
        mysql_results = cursor.fetchall()
        
        # **B∆Ø·ªöC 7: Build response**
        current_group_ids.clear()
        current_group_ids.extend(max_group_ids)
        
        filter_params.clear()
        filter_params.update({
            "search": query,
            "type": device_type,
            "method": "superlative_mongodb_max_with_units",
            "target_field": target_field,
            "required_units": ",".join(required_units)
        })
        
        device_name_map = {
            "laptop": "laptop", "phone": "ƒëi·ªán tho·∫°i", 
            "wireless_earphone": "tai nghe kh√¥ng d√¢y", "wired_earphone": "tai nghe c√≥ d√¢y", 
            "headphone": "headphone", "backup_charger": "s·∫°c d·ª± ph√≤ng"
        }
        device_name = device_name_map.get(device_type, device_type)
        
        response = []
        response.append(f"**Top {device_name} c√≥ {field_name_vn} l·ªõn nh·∫•t**")
        response.append(f"Y√™u c·∫ßu: '{query}'")
        response.append(f"Ti√™u ch√≠: {field_name_vn} cao nh·∫•t (ƒë∆°n v·ªã: {', '.join(required_units)})")
        response.append(f"K·∫øt qu·∫£: {len(max_group_ids)} s·∫£n ph·∫©m h·ª£p l·ªá")
        response.append("")
        
        # Create mapping for easy lookup
        info_map = {info['group_id']: info for info in max_info}
        
        for i, result in enumerate(mysql_results, 1):
            group_id, group_name, brand, product_type, min_price, tags = result
            
            # Get MongoDB info
            mongo_info = info_map.get(group_id, {})
            field_value = mongo_info.get('field_value', 'N/A')
            numeric_value = mongo_info.get('numeric_value', 0)
            has_valid_unit = mongo_info.get('has_valid_unit', False)
            
            product_info = f"**{i}. {group_name}** - {brand}"
            product_info += f"\n   Group ID: {group_id}"
            product_info += f"\n   {field_name_vn}: {field_value}"
            if numeric_value > 0:
                product_info += f" (gi√° tr·ªã s·ªë: {numeric_value})"
            if has_valid_unit:
                product_info += " ‚úì"
            else:
                product_info += " (ƒë∆°n v·ªã kh√¥ng chu·∫©n)"
            product_info += f"\n   Gi√° t·ª´: {int(min_price):,} ƒë·ªìng" if min_price else "\n   üí∞ Gi√°: ƒêang c·∫≠p nh·∫≠t"
            
            response.append(product_info)
            
            
        
        # Th√™m th·ªëng k√™
        if max_info:
            max_value = max_info[0]['numeric_value']
            min_value = max_info[-1]['numeric_value']
            valid_units_count = sum(1 for info in max_info if info.get('has_valid_unit', False))
            
            response.append(f"üìà **Th·ªëng k√™ {field_name_vn}:**")
            response.append(f"   ‚Ä¢ Gi√° tr·ªã cao nh·∫•t: {max_value}")
            response.append(f"   ‚Ä¢ Gi√° tr·ªã th·∫•p nh·∫•t trong top: {min_value}")
            response.append(f"   ‚Ä¢ S·∫£n ph·∫©m c√≥ ƒë∆°n v·ªã h·ª£p l·ªá: {valid_units_count}/{len(max_info)}")
            response.append(f"   ‚Ä¢ ƒê∆°n v·ªã ƒë∆∞·ª£c ch·∫•p nh·∫≠n: {', '.join(required_units)}")
            response.append("")
        
        response.append("üí° **Ghi ch√∫:**")
        response.append(f"   ‚Ä¢ K·∫øt qu·∫£ ƒë∆∞·ª£c s·∫Øp x·∫øp theo {field_name_vn} t·ª´ cao ƒë·∫øn th·∫•p")
        response.append(f"   ‚Ä¢ Ch·ªâ t√≠nh c√°c s·∫£n ph·∫©m c√≥ ƒë∆°n v·ªã h·ª£p l·ªá: {', '.join(required_units)}")
        response.append("   ‚Ä¢ ‚úì = C√≥ ƒë∆°n v·ªã h·ª£p l·ªá, ‚ö†Ô∏è = ƒê∆°n v·ªã kh√¥ng chu·∫©n")
        
        cursor.close()
        conn.close()
        return "\n".join(response)
        
    except Exception as e:
        print(f"Error in handle_superlative_query: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # Fallback to simple approach if config fails
        try:
            return handle_superlative_query_fallback(query, device_type, top_k)
        except:
            return f"L·ªói t√¨m ki·∫øm {device_type} v·ªõi ti√™u ch√≠ 'l·ªõn nh·∫•t': {str(e)}"
    finally:
        mongodb.disconnect()

def handle_superlative_query_fallback(query: str, device_type: str, top_k: int = 5) -> str:
    """
    Fallback method khi config system fails.
    """
    try:
        from all_fields_by_class import device_type_to_class
    except ImportError:
        device_type_to_class = {
            "laptop": "com.eazybytes.model.Laptop",
            "phone": "com.eazybytes.model.Phone", 
            "wireless_earphone": "com.eazybytes.model.WirelessEarphone",
            "wired_earphone": "com.eazybytes.model.WiredEarphone",
            "headphone": "com.eazybytes.model.Headphone",
            "backup_charger": "com.eazybytes.model.BackupCharger"
        }
    
    # Simple field mapping as fallback
    fallback_mapping = {
        "laptop": ("ram", "RAM"),
        "phone": ("batteryCapacity", "Dung l∆∞·ª£ng pin"),
        "wireless_earphone": ("batteryLife", "Th·ªùi l∆∞·ª£ng pin"),
        "headphone": ("batteryLife", "Th·ªùi l∆∞·ª£ng pin"),
        "backup_charger": ("batteryCapacity", "Dung l∆∞·ª£ng pin"),
        "wired_earphone": ("cableLength", "ƒê·ªô d√†i d√¢y")
    }
    
    target_field, field_name_vn = fallback_mapping.get(device_type, ("ram", "RAM"))
    
    try:
        db = mongodb.connect()
        if db is None:
            return "Kh√¥ng th·ªÉ k·∫øt n·ªëi MongoDB."
        
        collection = mongodb.get_collection("baseProduct")
        if collection is None:
            return "Kh√¥ng t√¨m th·∫•y collection baseProduct."
        
        # Simple aggregation without unit validation
        base_filter = {}
        if device_type in device_type_to_class:
            base_filter["_class"] = device_type_to_class[device_type]
        
        pipeline = [
            {"$match": base_filter},
            {
                "$addFields": {
                    "numeric_value": {
                        "$convert": {
                            "input": {
                                "$arrayElemAt": [
                                    {
                                        "$map": {
                                            "input": {"$regexFindAll": {"input": f"${target_field}", "regex": r"(\d+(?:\.\d+)?)"}},
                                            "as": "match",
                                            "in": "$match.match"
                                        }
                                    },
                                    0
                                ]
                            },
                            "to": "double",
                            "onError": 0
                        }
                    }
                }
            },
            {"$match": {"numeric_value": {"$gt": 0}}},
            {"$sort": {"numeric_value": -1}},
            {"$limit": top_k * 2},
            {"$project": {"_id": 1, "productName": 1, "brand": 1, target_field: 1, "numeric_value": 1}}
        ]
        
        results = list(collection.aggregate(pipeline))
        
        if not results:
            return f"Kh√¥ng t√¨m th·∫•y {device_type} n√†o c√≥ {field_name_vn} h·ª£p l·ªá."
        
        # Convert to group_ids
        max_group_ids = []
        for result in results:
            if len(max_group_ids) >= top_k:
                break
                
            product_id = str(result['_id'])
            mysql_result = find_group_id_by_product_id(product_id)
            
            if mysql_result.get("status") == "success":
                group_id = mysql_result.get("group_id")
                if group_id and group_id not in max_group_ids:
                    max_group_ids.append(group_id)
        
        if not max_group_ids:
            return f"Kh√¥ng t√¨m th·∫•y mapping cho {device_type}."
        
        current_group_ids.clear()
        current_group_ids.extend(max_group_ids)
        
        return f"T√¨m th·∫•y {len(max_group_ids)} {device_type} c√≥ {field_name_vn} cao nh·∫•t (fallback mode)."
        
    except Exception as e:
        return f"L·ªói fallback: {str(e)}"
    finally:
        mongodb.disconnect()

def detailed_specs_search_hybrid(query: str, device_type: str, top_k: int = 5) -> str:
    """
    H√†m t√¨m ki·∫øm c·∫•u h√¨nh chi ti·∫øt v√† th√¥ng s·ªë k·ªπ thu·∫≠t k·∫øt h·ª£p MongoDB v√† Elasticsearch.
    
    Workflow:
    1. MongoDB: T√¨m ki·∫øm structured data (RAM, CPU, storage, specifications)
    2. Elasticsearch: T√¨m ki·∫øm text descriptions v√† detailed features
    3. K·∫øt h·ª£p v√† rank k·∫øt qu·∫£ t·ª´ c·∫£ hai ngu·ªìn
    4. Tr·∫£ v·ªÅ th√¥ng tin chi ti·∫øt v·ªÅ c·∫•u h√¨nh v√† th√¥ng s·ªë k·ªπ thu·∫≠t
    
    Args:
        query (str): Y√™u c·∫ßu ng∆∞·ªùi d√πng v·ªÅ c·∫•u h√¨nh/th√¥ng s·ªë k·ªπ thu·∫≠t 
                    (v√≠ d·ª•: "32GB RAM RTX 4070 gaming hi·ªáu nƒÉng cao")
        device_type (str): Lo·∫°i thi·∫øt b·ªã ("laptop", "phone", "wireless_earphone", "wired_earphone", "headphone", "backup_charger")
        top_k (int): S·ªë l∆∞·ª£ng s·∫£n ph·∫©m mu·ªën hi·ªÉn th·ªã (default: 5)
        
    Returns:
        str: K·∫øt qu·∫£ chi ti·∫øt v·ªõi c·∫•u h√¨nh v√† th√¥ng s·ªë k·ªπ thu·∫≠t t·ª´ MongoDB + Elasticsearch
        
    Examples:
        >>> detailed_specs_search_hybrid("32GB RAM i7 RTX 4070", "laptop", 5)
        >>> detailed_specs_search_hybrid("camera 48MP pin 4000mAh", "phone", 3)
        >>> detailed_specs_search_hybrid("pin 30h Bluetooth 5.3", "wireless_earphone", 4)
    """
    current_group_ids.clear()
    filter_params.clear()
    
    try:
        # **B∆Ø·ªöC 1: Validate device_type**
        valid_device_types = ["laptop", "phone", "wireless_earphone", "wired_earphone", "headphone", "backup_charger"]
        if device_type not in valid_device_types:
            return f"Lo·∫°i thi·∫øt b·ªã kh√¥ng h·ª£p l·ªá: '{device_type}'. C√°c lo·∫°i h·ªó tr·ª£: {', '.join(valid_device_types)}"
        
        print(f"Hybrid search for {device_type}: '{query}'")
        
        # **B∆Ø·ªöC 1.5: Detect "l·ªõn nh·∫•t/cao nh·∫•t" queries**
        superlative_keywords = [
            "l·ªõn nh·∫•t", "cao nh·∫•t", "t·ªëi ƒëa", "max", "maximum", "highest", "biggest", "largest",
            "m·∫°nh nh·∫•t", "nhanh nh·∫•t", "t·ªët nh·∫•t", "best", "fastest", "strongest",
            "pin cao nh·∫•t", "ram l·ªõn nh·∫•t", "dung l∆∞·ª£ng l·ªõn nh·∫•t", "camera cao nh·∫•t"
        ]
        
        is_superlative_query = any(keyword in query.lower() for keyword in superlative_keywords)
        
        if is_superlative_query:
            print(f"Detected superlative query: '{query}'")
            # Handle superlative queries v·ªõi MongoDB aggregation pipeline
            superlative_result = handle_superlative_query(query, device_type, top_k)
            if superlative_result:
                return superlative_result
        
        # **B∆Ø·ªöC 2: MongoDB Search cho structured requirements**
        mongodb_product_ids = []
        mongodb_search_info = {}
        
        print(f"Step 1: MongoDB search for structured requirements...")
        mongo_search_result = mongodb_search_specific_requirements_get_product_ids(
            query=query,
            device_type=device_type,
            top_k=top_k * 3  # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ c√≥ nhi·ªÅu l·ª±a ch·ªçn
        )
        
        if mongo_search_result.get("success") and mongo_search_result.get("product_ids"):
            mongodb_product_ids = mongo_search_result["product_ids"]
            mongodb_search_info = mongo_search_result["search_info"]
            print(f"MongoDB found {len(mongodb_product_ids)} product_ids")
        else:
            print("MongoDB search returned no results")
        
        # **B∆Ø·ªöC 3: Convert MongoDB product_ids to group_ids**
        mongodb_group_ids = []
        if mongodb_product_ids:
            print(f"Step 2: Converting {len(mongodb_product_ids)} product_ids to group_ids...")
            for product_id in mongodb_product_ids:
                mysql_result = find_group_id_by_product_id(str(product_id))
                if mysql_result.get("status") == "success":
                    group_id = mysql_result.get("group_id")
                    if group_id and group_id not in mongodb_group_ids:
                        mongodb_group_ids.append(group_id)
            print(f"Converted to {len(mongodb_group_ids)} group_ids")
        
        # **B∆Ø·ªöC 4: Elasticsearch Search cho text descriptions**
        elasticsearch_group_ids = []
        elasticsearch_scores = {}
        
        print(f"Step 3: Elasticsearch search for text descriptions...")
        try:
            # N·∫øu c√≥ MongoDB group_ids, c√≥ th·ªÉ filter ho·∫∑c kh√¥ng filter t√πy strategy
            es_filter_ids = mongodb_group_ids
            # Kh√¥ng filter ƒë·ªÉ c√≥ th√™m k·∫øt qu·∫£ t·ª´ Elasticsearch
            
            es_results = search_elasticsearch(
                query=query,
                ids=es_filter_ids,
                size=top_k * 2
            )
            
            if es_results:
                for hit in es_results:
                    group_id = hit.get('group_id')
                    score = hit.get('_score', 0)
                    if group_id:
                        group_id = int(group_id)
                        if group_id not in elasticsearch_group_ids:
                            elasticsearch_group_ids.append(group_id)
                            elasticsearch_scores[group_id] = score
                print(f"Elasticsearch found {len(elasticsearch_group_ids)} group_ids")
            else:
                print("Elasticsearch returned no results")
        except Exception as es_error:
            print(f"Elasticsearch search failed: {str(es_error)}")
        
        # **B∆Ø·ªöC 5: K·∫øt h·ª£p k·∫øt qu·∫£ v·ªõi weighted scoring**
        print("Step 4: Combining MongoDB and Elasticsearch results...")
        
        # T·∫°o scoring map k·∫øt h·ª£p
        combined_scores = {}
        
        # MongoDB scores (weight 1.3 - cao h∆°n v√¨ structured data ch√≠nh x√°c h∆°n)
        for i, group_id in enumerate(mongodb_group_ids):
            mongodb_score = (len(mongodb_group_ids) - i) * 1.3
            combined_scores[group_id] = combined_scores.get(group_id, 0) + mongodb_score
        
        # Elasticsearch scores (weight 1.0)
        for i, group_id in enumerate(elasticsearch_group_ids):
            es_score = elasticsearch_scores.get(group_id, len(elasticsearch_group_ids) - i) * 1.0
            combined_scores[group_id] = combined_scores.get(group_id, 0) + es_score
        
        # Sort by combined score
        sorted_groups = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)
        final_group_ids = [group_id for group_id, score in sorted_groups[:top_k]]
        
        if not final_group_ids:
            return f"Kh√¥ng t√¨m th·∫•y {device_type} n√†o ph√π h·ª£p v·ªõi y√™u c·∫ßu: '{query}'"
        
        search_method = f"Hybrid (MongoDB: {len(mongodb_group_ids)}, ES: {len(elasticsearch_group_ids)})"
        
        # **B∆Ø·ªöC 6: L·∫•y th√¥ng tin chi ti·∫øt t·ª´ MySQL**
        print(f"Step 5: Getting detailed info for {len(final_group_ids)} group_ids...")
        
        conn = mysql.connect()
        cursor = conn.cursor()
        
        # L·∫•y th√¥ng tin chi ti·∫øt
        placeholders = ','.join(['%s'] * len(final_group_ids))
        detail_sql = f"""
            SELECT 
                gp.group_id, 
                gp.group_name, 
                gp.brand,
                gp.type,
                MIN(gpj.default_current_price) AS min_price,
                GROUP_CONCAT(DISTINCT t.tag_name ORDER BY t.tag_name) AS tags
            FROM group_product gp
            LEFT JOIN group_product_junction gpj ON gp.group_id = gpj.group_id
            LEFT JOIN group_tags gt ON gp.group_id = gt.group_id
            LEFT JOIN tags t ON gt.tag_id = t.tag_id
            WHERE gp.group_id IN ({placeholders}) AND gp.type = %s
            GROUP BY gp.group_id, gp.group_name, gp.brand, gp.type
            ORDER BY FIELD(gp.group_id, {placeholders})
        """
        
        params = final_group_ids + [device_type] + final_group_ids
        cursor.execute(detail_sql, params)
        mysql_results = cursor.fetchall()
        
        # **B∆Ø·ªöC 7: Build response**
        current_group_ids.extend(final_group_ids)
        
        # Update filter_params
        filter_params.update({
            "search": query,
            "type": device_type,
            "method": "hybrid_mongodb_elasticsearch"
        })
        
        device_name_map = {
            "laptop": "laptop",
            "phone": "ƒëi·ªán tho·∫°i", 
            "wireless_earphone": "tai nghe kh√¥ng d√¢y",
            "wired_earphone": "tai nghe c√≥ d√¢y", 
            "headphone": "headphone",
            "backup_charger": "s·∫°c d·ª± ph√≤ng"
        }
        device_name = device_name_map.get(device_type, device_type)
        
        response = []
        response.append(f"**T√¨m ki·∫øm c·∫•u h√¨nh chi ti·∫øt {device_name}**")
        response.append(f"Y√™u c·∫ßu: '{query}'")
        response.append(f"Ph∆∞∆°ng ph√°p: {search_method}")
        response.append(f"K·∫øt qu·∫£: {len(final_group_ids)} s·∫£n ph·∫©m")
        response.append("")
        
        # Hi·ªÉn th·ªã MongoDB search conditions n·∫øu c√≥
        if mongodb_search_info and mongodb_search_info.get("applied_conditions"):
            response.append("**ƒêi·ªÅu ki·ªán k·ªπ thu·∫≠t ƒë√£ √°p d·ª•ng:**")
            for condition in mongodb_search_info["applied_conditions"]:
                field = condition["field"]
                operator = condition["operator"]
                value = condition["value"]
                
                # Field translations
                field_translations = {
                    "ram": "RAM", "storage": "B·ªô nh·ªõ", 
                    "processorModel": "Processor", "processor": "Processor",
                    "graphicCard": "Card ƒë·ªì h·ªça", "batteryCapacity": "Dung l∆∞·ª£ng pin",
                    "rearCameraResolution": "Camera sau", "frontCameraResolution": "Camera tr∆∞·ªõc",
                    "batteryLife": "Th·ªùi l∆∞·ª£ng pin", "screenSize": "M√†n h√¨nh",
                    "refreshRate": "T·∫ßn s·ªë qu√©t", "brand": "Th∆∞∆°ng hi·ªáu",
                    "productName": "T√™n s·∫£n ph·∫©m", "audioTechnology": "C√¥ng ngh·ªá √¢m thanh",
                    "connectionTechnology": "C√¥ng ngh·ªá k·∫øt n·ªëi", "chargingCaseBatteryLife": "Pin h·ªôp s·∫°c"
                }
                
                field_vn = field_translations.get(field, field)
                
                if operator in ["gte", "gt"]:
                    response.append(f"   ‚úì {field_vn} ‚â• {value}")
                elif operator in ["lte", "lt"]:
                    response.append(f"   ‚úì {field_vn} ‚â§ {value}")
                elif operator == "eq":
                    response.append(f"   ‚úì {field_vn} = {value}")
                elif operator == "regex":
                    response.append(f"   ‚úì {field_vn} ch·ª©a '{value}'")
                elif operator == "elemMatch":
                    response.append(f"   ‚úì {field_vn} c√≥ '{value}'")
                else:
                    response.append(f"   ‚úì {field_vn}: {value}")
            response.append("")
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        response.append("**Danh s√°ch s·∫£n ph·∫©m ph√π h·ª£p:**")
        response.append("")
        
        for i, result in enumerate(mysql_results, 1):
            group_id, group_name, brand, product_type, min_price, tags = result
            
            # L·∫•y combined score ƒë·ªÉ hi·ªÉn th·ªã
            combined_score = combined_scores.get(group_id, 0)
            
            product_info = f"**{i}. {group_name}** - {brand}"
            product_info += f"\n  Group ID: {group_id}"
            product_info += f"\n  Gi√° t·ª´: {int(min_price):,} ƒë·ªìng" if min_price else "\n   üí∞ Gi√°: ƒêang c·∫≠p nh·∫≠t"
            product_info += f"\n  Score: {combined_score:.1f}"
            
            # MongoDB vs Elasticsearch indicator
            in_mongo = group_id in mongodb_group_ids
            in_es = group_id in elasticsearch_group_ids
            source_indicator = ""
            if in_mongo and in_es:
                source_indicator = " (MongoDB + ES)"
            elif in_mongo:
                source_indicator = " (MongoDB)"
            elif in_es:
                source_indicator = " (Elasticsearch)"
            product_info += source_indicator
            
            response.append(product_info)
            response.append("")
        
        cursor.close()
        conn.close()
        return "\n".join(response)
        
    except Exception as e:
        print(f"Error in detailed_specs_search_hybrid: {str(e)}")
        import traceback
        traceback.print_exc()
        return f"L·ªói t√¨m ki·∫øm {device_type}: {str(e)}"



